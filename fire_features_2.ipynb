{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b59b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import path\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "np.set_printoptions(threshold=100000)\n",
    "from shapely.geometry import Polygon, Point, MultiPoint\n",
    "from shapely.ops import cascaded_union, unary_union, transform\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import shapely.wkt\n",
    "from shapely.validation import explain_validity,make_valid\n",
    "import xarray as xr\n",
    "import pygeos as pg\n",
    "import time\n",
    "import seaborn as sns\n",
    "from my_functions import sat_vap_press, vap_press, hot_dry_windy, haines\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from os.path import exists\n",
    "\n",
    "from timezonefinder import TimezoneFinder\n",
    "import pytz\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f313888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/lthapa/ML_daily/fire_polygons/august_complex_VIIRS_daily_12Z_day_start.geojson\n",
      "           day  fire area (ha)  fire area (m2)  fire area (acre)\n",
      "0   2020-08-16      462.348326    4.623483e+06       1142.462713\n",
      "1   2020-08-17      308.435684    3.084357e+06        762.144575\n",
      "2   2020-08-18    24154.183301    2.415418e+08      59684.986938\n",
      "3   2020-08-19    19857.760979    1.985776e+08      49068.527378\n",
      "4   2020-08-20    13023.242432    1.302324e+08      32180.432049\n",
      "5   2020-08-21     8646.957847    8.646958e+07      21366.632841\n",
      "6   2020-08-22     5823.917637    5.823918e+07      14390.900481\n",
      "7   2020-08-23     1912.976370    1.912976e+07       4726.964610\n",
      "8   2020-08-24     5610.498963    5.610499e+07      13863.542937\n",
      "9   2020-08-25     3226.761171    3.226761e+07       7973.326852\n",
      "10  2020-08-26     3318.487209    3.318487e+07       8199.981894\n",
      "11  2020-08-27     4218.567013    4.218567e+07      10424.079089\n",
      "12  2020-08-28     4343.039983    4.343040e+07      10731.651799\n",
      "13  2020-08-29     3577.541067    3.577541e+07       8840.103977\n",
      "14  2020-08-30     3783.674530    3.783675e+07       9349.459764\n",
      "15  2020-08-31    10379.818531    1.037982e+08      25648.531591\n",
      "16  2020-09-01    11330.589683    1.133059e+08      27997.887106\n",
      "17  2020-09-02     4118.437474    4.118437e+07      10176.658999\n",
      "18  2020-09-03     3666.796599    3.666797e+07       9060.654397\n",
      "19  2020-09-04    10146.805121    1.014681e+08      25072.755455\n",
      "20  2020-09-05     5563.142764    5.563143e+07      13746.525771\n",
      "21  2020-09-06     6525.774095    6.525774e+07      16125.187788\n",
      "22  2020-09-07    18283.953198    1.828395e+08      45179.648351\n",
      "23  2020-09-08    66260.529817    6.626053e+08     163729.769178\n",
      "24  2020-09-09    22917.128400    2.291713e+08      56628.224275\n",
      "25  2020-09-10     8864.934020    8.864934e+07      21905.251964\n",
      "26  2020-09-11     3740.268270    3.740268e+07       9242.202894\n",
      "27  2020-09-12     6083.308992    6.083309e+07      15031.856519\n",
      "28  2020-09-13    13718.529214    1.371853e+08      33898.485687\n",
      "29  2020-09-14     9169.407828    9.169408e+07      22657.606744\n",
      "30  2020-09-15     7452.023303    7.452023e+07      18413.949581\n",
      "31  2020-09-16     5550.261120    5.550261e+07      13714.695227\n",
      "32  2020-09-17     4615.516967    4.615517e+07      11404.942425\n",
      "33  2020-09-18     1475.395509    1.475396e+07       3645.702302\n",
      "34  2020-09-19     2529.554759    2.529555e+07       6250.529810\n",
      "35  2020-09-20     2934.248262    2.934248e+07       7250.527455\n",
      "36  2020-09-21     1707.262971    1.707263e+07       4218.646801\n",
      "37  2020-09-22     2643.753979    2.643754e+07       6532.716083\n",
      "38  2020-09-23     1598.133465    1.598133e+07       3948.987792\n",
      "39  2020-09-24     1314.167505    1.314168e+07       3247.307905\n",
      "40  2020-09-25     1345.528312    1.345528e+07       3324.800460\n",
      "41  2020-09-26      881.566458    8.815665e+06       2178.350717\n",
      "42  2020-09-27    14641.888432    1.464189e+08      36180.106315\n",
      "43  2020-09-28    14028.608904    1.402861e+08      34664.692602\n",
      "44  2020-09-29     3553.127776    3.553128e+07       8779.778736\n",
      "45  2020-09-30     4348.839880    4.348840e+07      10745.983345\n",
      "46  2020-10-01     3843.151573    3.843152e+07       9496.427536\n",
      "47  2020-10-02     2826.404441    2.826404e+07       6984.045373\n",
      "48  2020-10-03     7471.215553    7.471216e+07      18461.373631\n",
      "49  2020-10-04     1556.944916    1.556945e+07       3847.210888\n",
      "50  2020-10-05     2008.381935    2.008382e+07       4962.711761\n",
      "51  2020-10-06     3435.694464    3.435694e+07       8489.601020\n",
      "52  2020-10-07     1724.543779    1.724544e+07       4261.347679\n",
      "53  2020-10-08     2304.802599    2.304803e+07       5695.167221\n",
      "54  2020-10-09      411.377396    4.113774e+06       1016.513545\n",
      "55  2020-10-10        0.234739    2.347392e+03          0.580040\n",
      "56  2020-10-11      105.267331    1.052673e+06        260.115574\n",
      "57  2020-10-12       49.866434    4.986643e+05        123.219959\n",
      "58  2020-10-13       89.298261    8.929826e+05        220.656003\n",
      "59  2020-10-14      507.867071    5.078671e+06       1254.939534\n",
      "60  2020-10-15      419.371196    4.193712e+06       1036.266225\n",
      "61  2020-10-16       71.692862    7.169286e+05        177.153062\n",
      "62  2020-10-17       49.143499    4.914350e+05        121.433587\n",
      "63  2020-10-18       26.270518    2.627052e+05         64.914450\n",
      "64  2020-10-19        4.700445    4.700445e+04         11.614800\n",
      "66  2020-10-21        0.933163    9.331626e+03          2.305845\n",
      "67  2020-10-22        1.080103    1.080103e+04          2.668934\n",
      "69  2020-10-25        1.781260    1.781260e+04          4.401493\n",
      "70  2020-10-27       10.957096    1.095710e+05         27.074983\n",
      "73  2020-10-30        0.226300    2.262996e+03          0.559186\n",
      "/data2/lthapa/ML_daily/fire_polygons/bobcat_VIIRS_daily_12Z_day_start.geojson\n",
      "           day  fire area (ha)  fire area (m2)  fire area (acre)\n",
      "0   2020-09-05       11.717144    1.171714e+05         28.953063\n",
      "1   2020-09-06     3513.703904    3.513704e+07       8682.362348\n",
      "2   2020-09-07     2388.008930    2.388009e+07       5900.770066\n",
      "3   2020-09-08     3674.077237    3.674077e+07       9078.644852\n",
      "4   2020-09-09     3149.484959    3.149485e+07       7782.377332\n",
      "5   2020-09-10     2162.059764    2.162060e+07       5342.449676\n",
      "6   2020-09-11     1560.980665    1.560981e+07       3857.183224\n",
      "7   2020-09-12     1174.333696    1.174334e+07       2901.778562\n",
      "8   2020-09-13     1865.051365    1.865051e+07       4608.541923\n",
      "9   2020-09-14     2132.675372    2.132675e+07       5269.840844\n",
      "10  2020-09-15     2190.483966    2.190484e+07       5412.685879\n",
      "11  2020-09-16     3332.026851    3.332027e+07       8233.438349\n",
      "12  2020-09-17     5100.145830    5.100146e+07      12602.460346\n",
      "13  2020-09-18     9617.459222    9.617459e+07      23764.741738\n",
      "14  2020-09-19     3144.016156    3.144016e+07       7768.863922\n",
      "15  2020-09-20     2290.047128    2.290047e+07       5658.706452\n",
      "16  2020-09-21     2230.203840    2.230204e+07       5510.833687\n",
      "17  2020-09-22      691.315066    6.913151e+06       1708.239528\n",
      "18  2020-09-23      376.964568    3.769646e+06        931.479447\n",
      "19  2020-09-24      263.876632    2.638766e+06        652.039157\n",
      "20  2020-09-25       47.535109    4.753511e+05        117.459254\n",
      "21  2020-09-26        8.433147    8.433147e+04         20.838305\n",
      "22  2020-09-27       65.625047    6.562505e+05        162.159492\n",
      "23  2020-09-28       10.870278    1.087028e+05         26.860457\n",
      "24  2020-09-29       47.053715    4.705372e+05        116.269731\n",
      "25  2020-09-30       26.001338    2.600134e+05         64.249307\n",
      "26  2020-10-01       13.960448    1.396045e+05         34.496268\n",
      "27  2020-10-02      157.642059    1.576421e+06        389.533528\n",
      "28  2020-10-03      113.144341    1.131443e+06        279.579667\n",
      "29  2020-10-04        8.188603    8.188603e+04         20.234039\n",
      "30  2020-10-05        2.286021    2.286021e+04          5.648757\n",
      "32  2020-10-10        0.697372    6.973723e+03          1.723207\n",
      "34  2020-10-15        2.473385    2.473385e+04          6.111735\n",
      "35  2020-10-16       43.239753    4.323975e+05        106.845430\n",
      "36  2020-10-25        2.625122    2.625122e+04          6.486676\n",
      "37  2020-10-26       16.465790    1.646579e+05         40.686968\n",
      "38  2020-10-27        0.734133    7.341325e+03          1.814041\n",
      "40  2020-10-29        0.517413    5.174128e+03          1.278527\n",
      "/data2/lthapa/ML_daily/fire_polygons/dolan_VIIRS_daily_12Z_day_start.geojson\n",
      "           day  fire area (ha)  fire area (m2)  fire area (acre)\n",
      "0   2020-08-18     1377.720089    1.377720e+07       3404.346340\n",
      "1   2020-08-19     2741.481668    2.741482e+07       6774.201201\n",
      "2   2020-08-20     2590.809165    2.590809e+07       6401.889447\n",
      "3   2020-08-21     2448.895865    2.448896e+07       6051.221683\n",
      "4   2020-08-22      911.705509    9.117055e+06       2252.824312\n",
      "5   2020-08-23      264.864532    2.648645e+06        654.480260\n",
      "6   2020-08-24      410.374484    4.103745e+06       1014.035351\n",
      "7   2020-08-25      172.442034    1.724420e+06        426.104266\n",
      "8   2020-08-26      420.338524    4.203385e+06       1038.656492\n",
      "9   2020-08-27      785.489392    7.854894e+06       1940.944288\n",
      "10  2020-08-28      602.739160    6.027392e+06       1489.368465\n",
      "11  2020-08-29     1037.160446    1.037160e+07       2562.823463\n",
      "12  2020-08-30      992.259920    9.922599e+06       2451.874262\n",
      "13  2020-08-31      565.106054    5.651061e+06       1396.377060\n",
      "14  2020-09-01      344.094307    3.440943e+06        850.257033\n",
      "15  2020-09-02      131.736266    1.317363e+06        325.520314\n",
      "16  2020-09-03      174.282593    1.742826e+06        430.652287\n",
      "17  2020-09-04      349.286303    3.492863e+06        863.086456\n",
      "18  2020-09-05      645.806766    6.458068e+06       1595.788518\n",
      "19  2020-09-06     1129.714679    1.129715e+07       2791.524971\n",
      "20  2020-09-07    12992.456307    1.299246e+08      32104.359536\n",
      "21  2020-09-08     7223.809081    7.223809e+07      17850.032239\n",
      "22  2020-09-09     3353.631881    3.353632e+07       8286.824378\n",
      "23  2020-09-10     1439.464629    1.439465e+07       3556.917097\n",
      "24  2020-09-11     1297.357387    1.297357e+07       3205.770102\n",
      "25  2020-09-12     1036.770278    1.036770e+07       2561.859356\n",
      "26  2020-09-13      334.974655    3.349747e+06        827.722372\n",
      "27  2020-09-14      477.719371    4.777194e+06       1180.444565\n",
      "28  2020-09-15     1252.123538    1.252124e+07       3093.997261\n",
      "29  2020-09-16      837.527168    8.375272e+06       2069.529632\n",
      "30  2020-09-18      315.265193    3.152652e+06        779.020293\n",
      "31  2020-09-19       37.382240    3.738224e+05         92.371515\n",
      "32  2020-09-20       70.187313    7.018731e+05        173.432851\n",
      "33  2020-09-21       20.140750    2.014075e+05         49.767793\n",
      "34  2020-09-22       17.730600    1.773060e+05         43.812312\n",
      "36  2020-09-29       33.739432    3.373943e+05         83.370136\n",
      "37  2020-09-30        9.678963    9.678963e+04         23.916718\n",
      "39  2020-10-18      329.289466    3.292895e+06        813.674271\n",
      "40  2020-10-19       80.075000    8.007500e+05        197.865325\n",
      "/data2/lthapa/ML_daily/fire_polygons/holiday_farm_VIIRS_daily_12Z_day_start.geojson\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           day  fire area (ha)  fire area (m2)  fire area (acre)\n",
      "0   2020-09-07    10792.578143    1.079258e+08      26668.460590\n",
      "1   2020-09-08    29824.069150    2.982407e+08      73695.274869\n",
      "2   2020-09-09    15993.245350    1.599325e+08      39519.309260\n",
      "3   2020-09-10     3429.773902    3.429774e+07       8474.971313\n",
      "4   2020-09-11     1558.734776    1.558735e+07       3851.633630\n",
      "5   2020-09-12     1051.709916    1.051710e+07       2598.775202\n",
      "6   2020-09-13      479.076534    4.790765e+06       1183.798115\n",
      "7   2020-09-14      939.721041    9.397210e+06       2322.050692\n",
      "8   2020-09-15      411.234019    4.112340e+06       1016.159261\n",
      "9   2020-09-16      923.746460    9.237465e+06       2282.577502\n",
      "10  2020-09-17      125.059424    1.250594e+06        309.021837\n",
      "12  2020-09-28        2.110240    2.110240e+04          5.214402\n",
      "13  2020-10-03       15.199213    1.519921e+05         37.557255\n",
      "14  2020-10-05        0.784476    7.844757e+03          1.938440\n",
      "15  2020-10-06        7.176656    7.176656e+04         17.733518\n",
      "16  2020-10-08        8.708374    8.708374e+04         21.518391\n",
      "/data2/lthapa/ML_daily/fire_polygons/creek_VIIRS_daily_12Z_day_start.geojson\n",
      "           day  fire area (ha)  fire area (m2)  fire area (acre)\n",
      "0   2020-09-04     1405.006406    1.405006e+07       3471.770828\n",
      "1   2020-09-05    40578.929372    4.057893e+08     100270.534478\n",
      "2   2020-09-06    11496.124050    1.149612e+08      28406.922527\n",
      "3   2020-09-07    24780.939209    2.478094e+08      61233.700784\n",
      "4   2020-09-08     6800.690465    6.800690e+07      16804.506138\n",
      "5   2020-09-09     5637.698194    5.637698e+07      13930.752237\n",
      "6   2020-09-10     3524.239965    3.524240e+07       8708.396954\n",
      "7   2020-09-11     3314.692752    3.314693e+07       8190.605791\n",
      "8   2020-09-12     3890.178242    3.890178e+07       9612.630435\n",
      "9   2020-09-13     7801.732216    7.801732e+07      19278.080306\n",
      "10  2020-09-14     2675.864891    2.675865e+07       6612.062145\n",
      "11  2020-09-15     4037.924017    4.037924e+07       9977.710246\n",
      "12  2020-09-16     8735.972699    8.735973e+07      21586.588539\n",
      "13  2020-09-17     1520.379537    1.520380e+07       3756.857837\n",
      "14  2020-09-18     2941.501150    2.941501e+07       7268.449342\n",
      "15  2020-09-19     1320.938687    1.320939e+07       3264.039495\n",
      "16  2020-09-20     2620.726063    2.620726e+07       6475.814103\n",
      "17  2020-09-21     2645.749531    2.645750e+07       6537.647090\n",
      "18  2020-09-22     1800.054882    1.800055e+07       4447.935613\n",
      "19  2020-09-23     1574.960645    1.574961e+07       3891.727754\n",
      "20  2020-09-24     1078.381480    1.078381e+07       2664.680636\n",
      "21  2020-09-25      813.845986    8.138460e+06       2011.013433\n",
      "22  2020-09-26      669.053127    6.690531e+06       1653.230278\n",
      "23  2020-09-27     1206.071763    1.206072e+07       2980.203327\n",
      "24  2020-09-28      949.556274    9.495563e+06       2346.353553\n",
      "25  2020-09-29      470.961514    4.709615e+06       1163.745902\n",
      "26  2020-09-30      518.174794    5.181748e+06       1280.409916\n",
      "27  2020-10-01     1114.233672    1.114234e+07       2753.271403\n",
      "28  2020-10-02     1246.339514    1.246340e+07       3079.704939\n",
      "29  2020-10-03     1334.607012    1.334607e+07       3297.813926\n",
      "30  2020-10-04     3277.101513    3.277102e+07       8097.717839\n",
      "31  2020-10-05     1981.204477    1.981204e+07       4895.556263\n",
      "32  2020-10-06     2160.083881    2.160084e+07       5337.567270\n",
      "33  2020-10-07     1158.081042    1.158081e+07       2861.618255\n",
      "34  2020-10-08      320.818993    3.208190e+06        792.743731\n",
      "35  2020-10-09      279.796391    2.797964e+06        691.376881\n",
      "36  2020-10-10      528.331680    5.283317e+06       1305.507582\n",
      "37  2020-10-11      750.277375    7.502774e+06       1853.935394\n",
      "38  2020-10-12     1244.807644    1.244808e+07       3075.919689\n",
      "39  2020-10-13      516.350351    5.163504e+06       1275.901719\n",
      "40  2020-10-14     3301.962007    3.301962e+07       8159.148118\n",
      "41  2020-10-15      725.806346    7.258063e+06       1793.467481\n",
      "42  2020-10-16      723.998187    7.239982e+06       1788.999520\n",
      "43  2020-10-17      804.383227    8.043832e+06       1987.630954\n",
      "44  2020-10-18     1393.559330    1.393559e+07       3443.485104\n",
      "45  2020-10-19     1357.967282    1.357967e+07       3355.537154\n",
      "46  2020-10-20     1535.472330    1.535472e+07       3794.152127\n",
      "47  2020-10-21     1287.317660    1.287318e+07       3180.961938\n",
      "48  2020-10-22      708.160178    7.081602e+06       1749.863799\n",
      "49  2020-10-23      841.186158    8.411862e+06       2078.570997\n",
      "50  2020-10-24      590.828520    5.908285e+06       1459.937273\n",
      "51  2020-10-25      849.226069    8.492261e+06       2098.437617\n",
      "52  2020-10-26     1432.606653    1.432607e+07       3539.971039\n",
      "53  2020-10-27      879.759220    8.797592e+06       2173.885032\n",
      "54  2020-10-28      687.965695    6.879657e+06       1699.963232\n",
      "55  2020-10-29      279.860217    2.798602e+06        691.534596\n",
      "56  2020-10-30      212.059627    2.120596e+06        523.999338\n",
      "/data2/lthapa/ML_daily/fire_polygons/lake_VIIRS_daily_12Z_day_start.geojson\n",
      "           day  fire area (ha)  fire area (m2)  fire area (acre)\n",
      "0   2020-08-12     2056.378485    2.056378e+07       5081.311236\n",
      "1   2020-08-13      196.114730    1.961147e+06        484.599499\n",
      "2   2020-08-14      796.663316    7.966633e+06       1968.555053\n",
      "3   2020-08-15      918.180196    9.181802e+06       2268.823264\n",
      "4   2020-08-16      445.839030    4.458390e+06       1101.668242\n",
      "5   2020-08-17     2461.323352    2.461323e+07       6081.930004\n",
      "6   2020-08-18      431.101382    4.311014e+06       1065.251515\n",
      "7   2020-08-19      796.799837    7.967998e+06       1968.892396\n",
      "8   2020-08-20     1017.305845    1.017306e+07       2513.762742\n",
      "9   2020-08-21      632.931011    6.329310e+06       1563.972528\n",
      "10  2020-08-22       27.908175    2.790818e+05         68.961102\n",
      "11  2020-08-29        0.094198    9.419800e+02          0.232763\n",
      "/data2/lthapa/ML_daily/fire_polygons/cameron_peak_VIIRS_daily_12Z_day_start.geojson\n",
      "           day  fire area (ha)  fire area (m2)  fire area (acre)\n",
      "0   2020-08-12        9.932444    9.932444e+04         24.543070\n",
      "1   2020-08-13     1101.508247    1.101508e+07       2721.826878\n",
      "2   2020-08-14     2220.465757    2.220466e+07       5486.770885\n",
      "3   2020-08-15     2516.366366    2.516366e+07       6217.941290\n",
      "4   2020-08-16     1093.355494    1.093355e+07       2701.681427\n",
      "5   2020-08-17      650.569465    6.505695e+06       1607.557149\n",
      "6   2020-08-18      492.737434    4.927374e+06       1217.554199\n",
      "7   2020-08-19      232.844490    2.328445e+06        575.358734\n",
      "8   2020-08-20      109.750604    1.097506e+06        271.193743\n",
      "9   2020-08-21      467.587867    4.675879e+06       1155.409620\n",
      "10  2020-08-22     1273.805985    1.273806e+07       3147.574590\n",
      "11  2020-08-23      817.594767    8.175948e+06       2020.276669\n",
      "12  2020-08-24      251.534415    2.515344e+06        621.541540\n",
      "13  2020-08-25      144.230058    1.442301e+06        356.392474\n",
      "14  2020-08-26       38.315880    3.831588e+05         94.678539\n",
      "15  2020-08-27       59.543254    5.954325e+05        147.131382\n",
      "17  2020-09-02       17.912170    1.791217e+05         44.260972\n",
      "18  2020-09-03      362.960927    3.629609e+06        896.876451\n",
      "19  2020-09-04      275.008533    2.750085e+06        679.546084\n",
      "20  2020-09-05     5898.638422    5.898638e+07      14575.535542\n",
      "21  2020-09-06     7836.481923    7.836482e+07      19363.946833\n",
      "22  2020-09-07    10550.900270    1.055090e+08      26071.274568\n",
      "23  2020-09-13        9.899095    9.899095e+04         24.460663\n",
      "24  2020-09-14       53.011213    5.301121e+05        130.990708\n",
      "25  2020-09-15       65.106282    6.510628e+05        160.877622\n",
      "26  2020-09-16       13.643799    1.364380e+05         33.713828\n",
      "27  2020-09-17       19.432344    1.943234e+05         48.017323\n",
      "28  2020-09-18       35.564452    3.556445e+05         87.879761\n",
      "29  2020-09-19       56.506654    5.650665e+05        139.627942\n",
      "30  2020-09-20     1033.236682    1.033237e+07       2553.127841\n",
      "31  2020-09-21      115.559737    1.155597e+06        285.548109\n",
      "32  2020-09-22        0.926993    9.269926e+03          2.290599\n",
      "33  2020-09-23       86.808908    8.680891e+05        214.504813\n",
      "34  2020-09-24      216.163735    2.161637e+06        534.140590\n",
      "35  2020-09-25     3335.119569    3.335120e+07       8241.080454\n",
      "36  2020-09-26     3533.859320    3.533859e+07       8732.166380\n",
      "37  2020-09-27       10.150362    1.015036e+05         25.081544\n",
      "38  2020-09-28       73.621504    7.362150e+05        181.918737\n",
      "39  2020-09-29      434.591744    4.345917e+06       1073.876200\n",
      "40  2020-09-30      184.952765    1.849528e+06        457.018282\n",
      "41  2020-10-01      109.951141    1.099511e+06        271.689269\n",
      "42  2020-10-02      143.549244    1.435492e+06        354.710181\n",
      "43  2020-10-03       27.873105    2.787311e+05         68.874443\n",
      "44  2020-10-04      391.700011    3.917000e+06        967.890728\n",
      "45  2020-10-05      343.575550    3.435755e+06        848.975183\n",
      "46  2020-10-06      252.830116    2.528301e+06        624.743217\n",
      "47  2020-10-07      576.546495    5.765465e+06       1424.646388\n",
      "48  2020-10-08      415.631621    4.156316e+06       1027.025735\n",
      "49  2020-10-09     1165.542922    1.165543e+07       2880.056560\n",
      "50  2020-10-10      508.088954    5.080890e+06       1255.487805\n",
      "51  2020-10-12       62.301333    6.230133e+05        153.946595\n",
      "52  2020-10-13     1869.257973    1.869258e+07       4618.936452\n",
      "53  2020-10-14     9314.993306    9.314993e+07      23017.348460\n",
      "54  2020-10-15      348.864736    3.488647e+06        862.044763\n",
      "55  2020-10-16    10697.005466    1.069701e+08      26432.300508\n",
      "56  2020-10-17     1267.310855    1.267311e+07       3131.525123\n",
      "57  2020-10-18      281.214121    2.812141e+06        694.880093\n",
      "58  2020-10-19      557.773429    5.577734e+06       1378.258144\n",
      "59  2020-10-20      137.799326    1.377993e+06        340.502134\n",
      "60  2020-10-21      309.767617    3.097676e+06        765.435782\n",
      "61  2020-10-22       17.488230    1.748823e+05         43.213416\n",
      "62  2020-10-23      150.540084    1.505401e+06        371.984549\n",
      "63  2020-10-24      380.726915    3.807269e+06        940.776207\n",
      "/data2/lthapa/ML_daily/fire_polygons/pine_gulch_VIIRS_daily_12Z_day_start.geojson\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           day  fire area (ha)  fire area (m2)  fire area (acre)\n",
      "0   2020-07-31      218.783237    2.187832e+06        540.613379\n",
      "1   2020-08-01      212.047765    2.120478e+06        523.970027\n",
      "2   2020-08-02      365.701262    3.657013e+06        903.647819\n",
      "3   2020-08-03      514.201092    5.142011e+06       1270.590900\n",
      "4   2020-08-04     1978.795862    1.978796e+07       4889.604575\n",
      "5   2020-08-05     1160.362477    1.160362e+07       2867.255680\n",
      "6   2020-08-06      526.315535    5.263155e+06       1300.525687\n",
      "7   2020-08-07     2143.291383    2.143291e+07       5296.073007\n",
      "8   2020-08-08     1605.035890    1.605036e+07       3966.043684\n",
      "9   2020-08-09     1875.028140    1.875028e+07       4633.194535\n",
      "10  2020-08-10     2886.250809    2.886251e+07       7131.925749\n",
      "11  2020-08-11     4027.979592    4.027980e+07       9953.137572\n",
      "12  2020-08-12     3433.092426    3.433092e+07       8483.171386\n",
      "13  2020-08-13     1607.881547    1.607882e+07       3973.075303\n",
      "14  2020-08-14     1684.035838    1.684036e+07       4161.252554\n",
      "15  2020-08-15     3000.560227    3.000560e+07       7414.384321\n",
      "16  2020-08-16     2316.680623    2.316681e+07       5724.517820\n",
      "17  2020-08-17     1044.517822    1.044518e+07       2581.003539\n",
      "18  2020-08-18     7636.547386    7.636547e+07      18869.908590\n",
      "19  2020-08-19     1851.268065    1.851268e+07       4574.483389\n",
      "20  2020-08-20      954.445168    9.544452e+06       2358.434010\n",
      "21  2020-08-21     1165.045281    1.165045e+07       2878.826889\n",
      "22  2020-08-22     2345.204514    2.345205e+07       5795.000353\n",
      "23  2020-08-23      501.934521    5.019345e+06       1240.280201\n",
      "24  2020-08-24      556.318824    5.563188e+06       1374.663814\n",
      "25  2020-08-25       30.306492    3.030649e+05         74.887341\n",
      "28  2020-09-04        3.673166    3.673166e+04          9.076392\n"
     ]
    }
   ],
   "source": [
    "sit209=pd.read_csv('../Query2.txt')\n",
    "sit209.columns = ['INC209R_IDENTIFIER','INCIDENT_NAME','REPORT_FROM_DATE','REPORT_TO_DATE',\n",
    "              'RESTYP_IDENTIFIER', 'RESOURCE_QUANTITY','RESOURCE_PERSONNEL','CODE_NAME',\n",
    "              'INC_IDENTIFIER','PCT_CONTAINED_COMPLETED'] \n",
    "\n",
    "#all fires\n",
    "#fire_incidents = ['BOBCAT', 'DOLAN', 'HOLIDAY FARM','CREEK', 'LAKE', 'CAMERON PEAK', 'PINE GULCH', 'WILLIAMS FLATS', 'SHADY','PEDRO MOUNTAIN', 'WALKER', '204 COW']\n",
    "\n",
    "#2020 fires\n",
    "fire_incidents = ['AUGUST COMPLEX','BOBCAT', 'DOLAN', 'HOLIDAY FARM','CREEK', 'LAKE', 'CAMERON PEAK', 'PINE GULCH']\n",
    "#fire_incidents=['BOBCAT', 'DOLAN', 'HOLIDAY FARM','CREEK', 'LAKE', 'CAMERON PEAK', 'PINE GULCH']\n",
    "#fire_incidents = ['LAKE']\n",
    "\n",
    "path_poly = '/data2/lthapa/ML_daily/fire_polygons/'\n",
    "suffix_poly = 'Z_day_start.geojson'\n",
    "start_time=12\n",
    "for jj in range(len(fire_incidents)):\n",
    "    fire_name = fire_incidents[jj].lower().replace(' ','_')\n",
    "    print(path_poly+fire_name+'_VIIRS_daily_'+str(start_time)+suffix_poly)\n",
    "    fire_daily = gpd.read_file(path_poly+fire_name+'_VIIRS_daily_'+str(start_time)+suffix_poly)\n",
    "    fire_daily=fire_daily.drop(columns=['Current Overpass'])\n",
    "    fire_daily = fire_daily.drop(np.where(fire_daily['geometry']==None)[0])\n",
    "    fire_daily['fire area (ha)'] = fire_daily['geometry'].area/10000 #hectares. from m2\n",
    "    fire_daily.set_geometry(col='geometry', inplace=True) #designate the geometry column\n",
    "    fire_daily = fire_daily.rename(columns={'Current Day':'UTC Day', 'Local Day': str(start_time)+ 'Z Start Day'})\n",
    "    \n",
    "    fire_daily = fire_daily.iloc[np.array(fire_daily['UTC Day'].values,dtype='datetime64')<=np.datetime64('2020-10-31'),:]\n",
    "\n",
    "    \n",
    "    #merra\n",
    "    #me = merra_timeseries(fire_daily, start_time)\n",
    "    #print(me)\n",
    "    #me.to_csv('./fire_features/'+fire_name+'_Daily_MERRA_'+str(start_time)+'Z_day_start.csv') #daily averages\n",
    "\n",
    "    #hrrr\n",
    "    #hrrr = hrrr_timeseries(fire_daily,start_time)\n",
    "    #print(hrrr)\n",
    "    #hrrr.to_csv('./fire_features/'+fire_name+'_Daily_HRRR_'+str(start_time)+'Z_day_start.csv') #daily averages\n",
    "    \n",
    "    #hrrr with average wind\n",
    "    #hrrr = hrrr_timeseries_ws(fire_daily,start_time)\n",
    "    #print(hrrr)\n",
    "    #hrrr.to_csv('./fire_features/'+fire_name+'_Daily_HRRR_ws_'+str(start_time)+'Z_day_start.csv') #daily averages\n",
    "    \n",
    "    #rave\n",
    "    #rave=rave_timeseries(fire_daily,start_time)\n",
    "    #print(rave)\n",
    "    #rave.to_csv('./fire_features/'+fire_name+'_Daily_RAVE_'+str(start_time)+'Z_day_start.csv') #daily averages\n",
    "\n",
    "    #pws\n",
    "    #pws = pws_timeseries(fire_daily,start_time)\n",
    "    #print(pws)\n",
    "    #pws.to_csv('./fire_features/'+fire_name+'_Daily_PWS_'+str(start_time)+'Z_day_start.csv') #daily averages\n",
    "   \n",
    "    #hrrr_igbp\n",
    "    #igbp =hrrr_igbp_timeseries(fire_daily,start_time)\n",
    "    #print(igbp)\n",
    "    #igbp.to_csv('./fire_features/'+fire_name+'_Daily_IGBP_'+str(start_time)+'Z_day_start.csv') #daily averages\n",
    "\n",
    "    #esi \n",
    "    #esi = esi_timeseries(fire_daily,start_time)\n",
    "    #print(esi)\n",
    "    #esi.to_csv('./fire_features/'+fire_name+'_Daily_ESI_'+str(start_time)+'Z_day_start.csv') #daily averages\n",
    "    \n",
    "    #sit 209 data\n",
    "    #resources = resources_timeseries(fire_daily,start_time,sit209)\n",
    "    #print(resources)\n",
    "    #resources.to_csv('./fire_features/'+fire_name+'_Daily_Resources_'+str(start_time)+'Z_day_start.csv')\n",
    "    \n",
    "    #fuel loading (takes 20 mins to process AC on the 1km grid)\n",
    "    #fuel_loading = fuel_loading_timeseries(fire_daily,start_time)\n",
    "    #print(fuel_loading)\n",
    "    #fuel_loading.to_csv('./fire_features/'+fire_name+'_Daily_FUEL_LOADING_'+str(start_time)+'Z_day_start.csv') #daily averages\n",
    "    \n",
    "    #fire area\n",
    "    fire_area = fire_area_timeseries(fire_daily,start_time)\n",
    "    print(fire_area)\n",
    "    fire_area.to_csv('./fire_features/'+fire_name+'_Daily_FIRE_AREA_'+str(start_time)+'Z_day_start.csv') #daily averages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3cfd4",
   "metadata": {},
   "source": [
    "## Dataset-Dependent Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5b72d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### MERRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fe761",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def merra_timeseries(df,day_start_hour):\n",
    "    df_merra = pd.DataFrame({'day': np.zeros(len(df)),'temp':np.zeros(len(df)), 'vpd':np.zeros(len(df)), \n",
    "                             'wind':np.zeros(len(df)),'hd0w0':np.zeros(len(df)), 'hd1w0':np.zeros(len(df)),\n",
    "                             'hd2w0':np.zeros(len(df)),'hd3w0':np.zeros(len(df)), 'hd4w0':np.zeros(len(df)),\n",
    "                             'hd5w0':np.zeros(len(df))}) \n",
    "    \n",
    "    #do the intersection, in parallel\n",
    "    merra_intersections = Parallel(n_jobs=8)(delayed(calculate_intersection)\n",
    "                                 (fire_daily.iloc[ii:ii+1],'MERRA_GRID',0.5) \n",
    "                                 for ii in range(len(fire_daily)))\n",
    "    fire_merra_intersection=gpd.GeoDataFrame(pd.concat(merra_intersections, ignore_index=True))\n",
    "    fire_merra_intersection.set_geometry(col='geometry')\n",
    "    \n",
    "    \n",
    "    #loop over all of the days we have intersections\n",
    "    times_intersect = np.unique(fire_merra_intersection[str(day_start_hour)+ 'Z Start Day'].values)\n",
    "    times_utc = np.unique(fire_merra_intersection['UTC Day'].values)\n",
    "    \n",
    "    count = 0\n",
    "    for today in times_intersect:\n",
    "        #get the time\n",
    "        df_sub = fire_merra_intersection.iloc[np.where(fire_merra_intersection[str(day_start_hour)+ 'Z Start Day'].values==today)]\n",
    "        df_sub = df_sub.set_index([str(day_start_hour)+ 'Z Start Day', 'lat', 'lon'])\n",
    "        intersection_sub = df_sub.to_xarray() #polygon and weights for today\n",
    "        print(intersection_sub['weights'].sum(dim=['lat','lon']))\n",
    "        times_back = pd.date_range(start=np.datetime64(today)-np.timedelta64(5,'D'), end=np.datetime64(today)+np.timedelta64(1,'D'))\n",
    "        files_back = make_merra_file_namelist(times_back)\n",
    "        \n",
    "        #load in all the merra files associated with this lookback window\n",
    "        dat_merra = xr.open_mfdataset(files_back,concat_dim='time',combine='nested',compat='override', coords='all')\n",
    "    \n",
    "        #add the derived data (svp, vp, vpd)\n",
    "        dat_merra=dat_merra.assign(ESAT=sat_vap_press(dat_merra.TLML))\n",
    "        dat_merra=dat_merra.assign(E=vap_press(dat_merra.QLML, dat_merra.TLML))\n",
    "        dat_merra=dat_merra.assign(VPD=dat_merra.ESAT-dat_merra.E)\n",
    "        \n",
    "        merra_daily_mean = dat_merra.resample(time='24H',base=day_start_hour, label='left').mean(dim='time') #take the daily mean        \n",
    "        merra_daily_mean_region = merra_daily_mean.sel(lat = np.unique(intersection_sub['lat'].values),\n",
    "                                  lon = np.unique(intersection_sub['lon'].values)) #get the location of the overlaps\n",
    "        \n",
    "        hd0 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        hd1 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(1,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd2 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(2,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd3 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(3,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd4 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(4,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd5 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(5,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        w = np.nansum((merra_daily_mean_region['SPEEDLML'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        t = np.nansum((merra_daily_mean_region['TLML'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        \n",
    "        df_merra.iloc[count,:] = [today+ ' '+str(day_start_hour)+':00:00',t,hd0,w,hd0*w,hd1*w,hd2*w,hd3*w,hd4*w,hd5*w]\n",
    "        dat_merra.close()\n",
    "        count =count+1\n",
    "    return df_merra\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea10835",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_merra_file_namelist(time):\n",
    "    base_filename = '/data2/lthapa/YEAR/MERRA2/WESTUS_MERRA2_400.inst1_2d_lfo_Nx.FULLDATE.nc4'\n",
    "    base_filename_list = np.repeat(base_filename, len(time))\n",
    "\n",
    "    \n",
    "    for jj in range(len(time)):\n",
    "        base_filename_list[jj] = base_filename_list[jj].replace('YEAR',time[jj].strftime('%Y')).\\\n",
    "                                    replace('FULLDATE',time[jj].strftime('%Y%m%d'))\n",
    "        if (time[jj].strftime('%Y%m')=='202009'):\n",
    "            base_filename_list[jj] = base_filename_list[jj].replace('400','401')\n",
    "    return base_filename_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f27733",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### HRRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee31e0",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def hrrr_timeseries(df,day_start_hour):  \n",
    "    df_hrrr_derived = pd.DataFrame({'day': np.zeros(len(df)),'hd0w0':np.zeros(len(df)), 'hd1w0':np.zeros(len(df)),\n",
    "                             'hd2w0':np.zeros(len(df)),'hd3w0':np.zeros(len(df)), 'hd4w0':np.zeros(len(df)),\n",
    "                             'hd5w0':np.zeros(len(df))})\n",
    "    \n",
    "    df_hrrr_raw = pd.DataFrame({'temp_2m':np.zeros(len(df)), 'q_2m':np.zeros(len(df)), \n",
    "                             'gust_sfc':np.zeros(len(df)),'veggie':np.zeros(len(df)), 'dewpt':np.zeros(len(df)),\n",
    "                             'weasd':np.zeros(len(df)),'soilm':np.zeros(len(df)), 'esat_2m':np.zeros(len(df)),\n",
    "                             'e_2m': np.zeros(len(df)),'vpd_2m':np.zeros(len(df)), 'hwp':np.zeros(len(df)), \n",
    "                             'gust_sfc':np.zeros(len(df)),'veggie':np.zeros(len(df)), 'dewpt':np.zeros(len(df)),\n",
    "                             'veg_term':np.zeros(len(df)),'gust_max_term':np.zeros(len(df)), 'dd_term':np.zeros(len(df)),\n",
    "                             'mois_term': np.zeros(len(df)),'temp_2m':np.zeros(len(df)), 'q_2m':np.zeros(len(df)), \n",
    "                             'gust_sfc':np.zeros(len(df)),'snowc_term':np.zeros(len(df))})\n",
    "    \n",
    "    varis = ['temp_2m', 'q_2m','gust_sfc','veggie', 'dewpt','weasd','soilm', 'esat_2m','e_2m',\n",
    "             'vpd_2m', 'hwp','gust_sfc','veggie', 'dewpt','veg_term','gust_max_term', 'dd_term',\n",
    "            'mois_term','temp_2m', 'q_2m','gust_sfc','snowc_term']\n",
    "    \n",
    "    #do the intersection, in parallel\n",
    "    tic=time.time()\n",
    "    hrrr_intersections = Parallel(n_jobs=8)(delayed(calculate_intersection)\n",
    "                                 (fire_daily.iloc[ii:ii+1],'HRRR_GRID',0.05) \n",
    "                                 for ii in range(len(fire_daily)))\n",
    "    fire_hrrr_intersection=gpd.GeoDataFrame(pd.concat(hrrr_intersections, ignore_index=True))\n",
    "    fire_hrrr_intersection.set_geometry(col='geometry')\n",
    "    toc = time.time()\n",
    "    print(toc-tic)\n",
    "    \n",
    "    \n",
    "    #loop over all of the days we have intersections\n",
    "    times_intersect = np.unique(fire_hrrr_intersection[str(day_start_hour)+ 'Z Start Day'].values)\n",
    "    times_utc = np.unique(fire_hrrr_intersection['UTC Day'].values)\n",
    "    \n",
    "    count = 0\n",
    "    for today in times_intersect:\n",
    "        print(today)\n",
    "        #get the time\n",
    "        df_sub = fire_hrrr_intersection.iloc[np.where(fire_hrrr_intersection[str(day_start_hour)+ 'Z Start Day'].values==today)]\n",
    "        df_sub = df_sub.set_index([str(day_start_hour)+ 'Z Start Day', 'row', 'col'])\n",
    "        df_sub=df_sub[~df_sub.index.duplicated()]\n",
    "        intersection_sub = df_sub.to_xarray() #polygon and weights for today\n",
    "        \n",
    "        times_back = pd.date_range(start=np.datetime64(today)-np.timedelta64(5,'D'), end=np.datetime64(today)+\n",
    "                                   np.timedelta64(1,'D'),freq='H')\n",
    "        files_back,times_back_used = make_file_namelist(times_back,'/data2/lthapa/ML_daily/pygraf/Processed_HRRR_YYYYMMDDHH.nc')\n",
    "\n",
    "        #load in all the merra files associated with this lookback window\n",
    "        dat_hrrr = xr.open_mfdataset(files_back,concat_dim='time',combine='nested',compat='override', coords='all')\n",
    "        dat_hrrr = dat_hrrr.assign_coords({'time': times_back_used})\n",
    "\n",
    "        #add the derived data (svp, vp, vpd)\n",
    "        dat_hrrr=dat_hrrr.assign(esat_2m=sat_vap_press(dat_hrrr.temp_2m))\n",
    "        dat_hrrr=dat_hrrr.assign(e_2m=vap_press(dat_hrrr.q_2m, dat_hrrr.temp_2m))\n",
    "        dat_hrrr=dat_hrrr.assign(VPD=dat_hrrr.esat_2m-dat_hrrr.e_2m)\n",
    "        \n",
    "        hrrr_daily_mean = dat_hrrr.resample(time='24H',base=day_start_hour, label='left').mean(dim='time') #take the daily mean        \n",
    "        \n",
    "        hrrr_daily_mean_region = hrrr_daily_mean.sel(grid_yt = np.unique(intersection_sub['row'].values),\n",
    "                                                    grid_xt = np.unique(intersection_sub['col'].values)) #get the location of the overlaps\n",
    "        print(hrrr_daily_mean_region['time'].values)\n",
    "        hd0 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        hd1 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(1,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd2 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(2,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd3 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(3,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd4 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(4,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd5 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(5,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        w = np.nansum((hrrr_daily_mean_region['gust_sfc'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        t = np.nansum((hrrr_daily_mean_region['temp_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        \n",
    "        df_hrrr_derived.iloc[count,:] = [today+ ' '+str(day_start_hour)+':00:00',hd0*w,hd1*w,hd2*w,hd3*w,hd4*w,hd5*w]\n",
    "        \n",
    "        for var in varis:\n",
    "            df_hrrr_raw[var].iloc[count] = np.nansum(intersection_sub['weights'].values*hrrr_daily_mean_region[var].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values, axis=(1,2))\n",
    "        \n",
    "        df_hrrr = pd.concat([df_hrrr_derived,df_hrrr_raw],axis=1)\n",
    "        dat_hrrr.close()\n",
    "        count =count+1\n",
    "    return df_hrrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c1619a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def hrrr_timeseries_ws(df,day_start_hour):  #with the wind speed\n",
    "    df_hrrr_derived = pd.DataFrame({'day': np.zeros(len(df)),'hd0w0':np.zeros(len(df)), 'hd1w0':np.zeros(len(df)),\n",
    "                             'hd2w0':np.zeros(len(df)),'hd3w0':np.zeros(len(df)), 'hd4w0':np.zeros(len(df)),\n",
    "                             'hd5w0':np.zeros(len(df))})\n",
    "    \n",
    "    df_hrrr_raw = pd.DataFrame({'temp_2m':np.zeros(len(df)), 'q_2m':np.zeros(len(df)), \n",
    "                             'wind_speed':np.zeros(len(df)),'veggie':np.zeros(len(df)), 'dewpt':np.zeros(len(df)),\n",
    "                             'weasd':np.zeros(len(df)),'soilm':np.zeros(len(df)), 'esat_2m':np.zeros(len(df)),\n",
    "                             'e_2m': np.zeros(len(df)),'vpd_2m':np.zeros(len(df)), 'hwp':np.zeros(len(df)), \n",
    "                             'veggie':np.zeros(len(df)), 'dewpt':np.zeros(len(df)),\n",
    "                             'veg_term':np.zeros(len(df)),'gust_max_term':np.zeros(len(df)), 'dd_term':np.zeros(len(df)),\n",
    "                             'mois_term': np.zeros(len(df)),'temp_2m':np.zeros(len(df)), 'q_2m':np.zeros(len(df)), \n",
    "                             'snowc_term':np.zeros(len(df))})\n",
    "    \n",
    "    varis = ['temp_2m', 'q_2m','wind_speed','veggie', 'dewpt','weasd','soilm', 'esat_2m','e_2m',\n",
    "             'vpd_2m', 'hwp','veggie', 'dewpt','veg_term','gust_max_term', 'dd_term',\n",
    "            'mois_term','temp_2m', 'q_2m','snowc_term']\n",
    "    \n",
    "    #do the intersection, in parallel\n",
    "    tic=time.time()\n",
    "    hrrr_intersections = Parallel(n_jobs=8)(delayed(calculate_intersection)\n",
    "                                 (fire_daily.iloc[ii:ii+1],'HRRR_GRID',0.05) \n",
    "                                 for ii in range(len(fire_daily)))\n",
    "    fire_hrrr_intersection=gpd.GeoDataFrame(pd.concat(hrrr_intersections, ignore_index=True))\n",
    "    fire_hrrr_intersection.set_geometry(col='geometry')\n",
    "    toc = time.time()\n",
    "    print(toc-tic)\n",
    "    \n",
    "    \n",
    "    #loop over all of the days we have intersections\n",
    "    times_intersect = np.unique(fire_hrrr_intersection[str(day_start_hour)+ 'Z Start Day'].values)\n",
    "    times_utc = np.unique(fire_hrrr_intersection['UTC Day'].values)\n",
    "    \n",
    "    count = 0\n",
    "    for today in times_intersect:\n",
    "        print(today)\n",
    "        #get the time\n",
    "        df_sub = fire_hrrr_intersection.iloc[np.where(fire_hrrr_intersection[str(day_start_hour)+ 'Z Start Day'].values==today)]\n",
    "        df_sub = df_sub.set_index([str(day_start_hour)+ 'Z Start Day', 'row', 'col'])\n",
    "        df_sub=df_sub[~df_sub.index.duplicated()]\n",
    "        intersection_sub = df_sub.to_xarray() #polygon and weights for today\n",
    "        \n",
    "        times_back = pd.date_range(start=np.datetime64(today)-np.timedelta64(5,'D'), end=np.datetime64(today)+\n",
    "                                   np.timedelta64(1,'D'),freq='H')\n",
    "        files_back,times_back_used = make_file_namelist(times_back,'/data2/lthapa/ML_daily/pygraf/Processed_HRRR_YYYYMMDDHH.nc')\n",
    "\n",
    "        #load in all the merra files associated with this lookback window\n",
    "        dat_hrrr = xr.open_mfdataset(files_back,concat_dim='time',combine='nested',compat='override', coords='all')\n",
    "        dat_hrrr = dat_hrrr.assign_coords({'time': times_back_used})\n",
    "\n",
    "        #add the derived data (svp, vp, vpd)\n",
    "        dat_hrrr=dat_hrrr.assign(esat_2m=sat_vap_press(dat_hrrr.temp_2m))\n",
    "        dat_hrrr=dat_hrrr.assign(e_2m=vap_press(dat_hrrr.q_2m, dat_hrrr.temp_2m))\n",
    "        dat_hrrr=dat_hrrr.assign(VPD=dat_hrrr.esat_2m-dat_hrrr.e_2m)\n",
    "        \n",
    "        hrrr_daily_mean = dat_hrrr.resample(time='24H',base=day_start_hour, label='left').mean(dim='time') #take the daily mean        \n",
    "        \n",
    "        hrrr_daily_mean_region = hrrr_daily_mean.sel(grid_yt = np.unique(intersection_sub['row'].values),\n",
    "                                                    grid_xt = np.unique(intersection_sub['col'].values)) #get the location of the overlaps\n",
    "        print(hrrr_daily_mean_region['time'].values)\n",
    "        hd0 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        hd1 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(1,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd2 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(2,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd3 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(3,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd4 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(4,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd5 = np.nansum((hrrr_daily_mean_region['vpd_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(5,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        w = np.nansum((hrrr_daily_mean_region['wind_speed'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        t = np.nansum((hrrr_daily_mean_region['temp_2m'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        \n",
    "        df_hrrr_derived.iloc[count,:] = [today+ ' '+str(day_start_hour)+':00:00',hd0*w,hd1*w,hd2*w,hd3*w,hd4*w,hd5*w]\n",
    "        \n",
    "        for var in varis:\n",
    "            df_hrrr_raw[var].iloc[count] = np.nansum(intersection_sub['weights'].values*hrrr_daily_mean_region[var].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values, axis=(1,2))\n",
    "        \n",
    "        df_hrrr = pd.concat([df_hrrr_derived,df_hrrr_raw],axis=1)\n",
    "        dat_hrrr.close()\n",
    "        count =count+1\n",
    "        print(df_hrrr)\n",
    "    return df_hrrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "810d43db",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_hrrr_file_namelist(time):\n",
    "    base_filename = '/data2/lthapa/ML_daily/pygraf/Processed_HRRR_YYYYMMDDHH.nc'\n",
    "    base_filename_list = np.array([])\n",
    "    times_back_used = np.array([])\n",
    "\n",
    "    \n",
    "    for jj in range(len(time)):\n",
    "        fname = base_filename.replace('YYYYMMDDHH',time[jj].strftime('%Y%m%d%H'))\n",
    "        if exists(fname):\n",
    "            base_filename_list = np.append(base_filename_list,fname)\n",
    "            times_back_used = np.append(times_back_used,time[jj])\n",
    "            \n",
    "    return base_filename_list, times_back_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eac975",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### RAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f830604",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rave_timeseries(df, day_start_hour):\n",
    "    varis = ['Mean_FRP', 'FRE', 'CO2', 'CO', 'SO2', 'OC', 'BC', 'PM2.5', 'NOx', 'NH3'] #don't need 'area', it's the area of each cell\n",
    "\n",
    "\n",
    "    #do the intersection, in parallel\n",
    "    rave_intersections = Parallel(n_jobs=8)(delayed(calculate_intersection)\n",
    "                                 (fire_daily.iloc[ii:ii+1],'RAVE_GRID',0.1) \n",
    "                                 for ii in range(len(fire_daily)))\n",
    "    fire_rave_intersection=gpd.GeoDataFrame(pd.concat(rave_intersections, ignore_index=True))\n",
    "    fire_rave_intersection.set_geometry(col='geometry')    \n",
    "    fire_rave_intersection = fire_rave_intersection.set_index([str(day_start_hour)+ 'Z Start Day', 'row', 'col'])\n",
    "    \n",
    "    fire_rave_intersection_xr = fire_rave_intersection.to_xarray()\n",
    "    \n",
    "    #load in rave data associated with the fire\n",
    "    times = pd.date_range(np.datetime64(df[str(day_start_hour)+ 'Z Start Day'].iloc[0]),\n",
    "                        np.datetime64(df[str(day_start_hour)+ 'Z Start Day'].iloc[len(df)-1])+\n",
    "                        np.timedelta64(1,'D'))\n",
    "    rave_filenames,times_back_used = make_file_namelist(times,'/data2/lthapa/YYYY/AprYYYY_to_OctYYYY/Hourly_Emissions_FV3_13km_YYYYMMDD0000_YYYYMMDD2300xr.nc')\n",
    "    dat_rave = xr.open_mfdataset(rave_filenames,concat_dim='Time',combine='nested',compat='override', coords='all')\n",
    "    dat_rave = dat_rave.assign_coords({'Time': dat_rave.time}) #assign coords so we can resample along time\n",
    "    dat_rave = dat_rave.resample(Time='24H',base=day_start_hour).sum(dim='Time') #take the daily sum\n",
    "    \n",
    "    \n",
    "    #select the locations and times we want\n",
    "    dat_rave_sub = dat_rave.isel(yFRP = fire_rave_intersection_xr['row'].values.astype(int), \n",
    "                    xFRP = fire_rave_intersection_xr['col'].values.astype(int)).sel(\n",
    "                    Time = pd.to_datetime(fire_rave_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values+\n",
    "                                         'T'+str(day_start_hour)+':00:00')) #these should be lined up correctly\n",
    "    ndays = len(fire_rave_intersection_xr[str(day_start_hour)+ 'Z Start Day'])\n",
    "    \n",
    "    #preallocate space for the output\n",
    "    df_rave = pd.DataFrame({'day':np.zeros(ndays),'Mean_FRP':np.zeros(ndays),\\\n",
    "                          'FRE':np.zeros(ndays),  'CO2':np.zeros(ndays),  'CO':np.zeros(ndays),\\\n",
    "                          'SO2':np.zeros(ndays),  'OC':np.zeros(ndays),  'BC':np.zeros(ndays),\\\n",
    "                          'PM2.5':np.zeros(ndays),  'NOx':np.zeros(ndays),  'NH3':np.zeros(ndays)})\n",
    "\n",
    "    df_rave['day'].iloc[:] = pd.to_datetime(fire_rave_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values+\n",
    "                                         'T'+str(day_start_hour)+':00:00')\n",
    "    for var in varis:\n",
    "        df_rave[var] = np.nansum(fire_rave_intersection_xr['weights'].values*dat_rave_sub[var].values, axis=(1,2))\n",
    "    \n",
    "    return df_rave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768baf47",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_rave_file_namelist(time):\n",
    "    base_filename = '/data2/lthapa/YEAR/AprYEAR_to_OctYEAR/Hourly_Emissions_FV3_13km_FULLDATE0000_FULLDATE2300xr.nc'\n",
    "    base_filename_list = np.repeat(base_filename, len(time))\n",
    "\n",
    "    \n",
    "    for jj in range(len(time)):\n",
    "        base_filename_list[jj] = base_filename_list[jj].replace('YEAR',time[jj].strftime('%Y')).\\\n",
    "                                    replace('FULLDATE',time[jj].strftime('%Y%m%d'))\n",
    "    return base_filename_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68f7a8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### PWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb108c85",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pws_timeseries(df, day_start_hour):\n",
    "    #do the intersection, in parallel\n",
    "    tic = time.time()\n",
    "    pws_intersections = Parallel(n_jobs=8)(delayed(calculate_intersection)\n",
    "                                 (fire_daily.iloc[ii:ii+1],'PWS_GRID',0.05) \n",
    "                                 for ii in range(len(fire_daily)))\n",
    "    toc = time.time()\n",
    "    print(toc-tic)\n",
    "    fire_pws_intersection=gpd.GeoDataFrame(pd.concat(pws_intersections, ignore_index=True))\n",
    "    fire_pws_intersection.set_geometry(col='geometry')\n",
    "    fire_pws_intersection = fire_pws_intersection.set_index([str(day_start_hour)+ 'Z Start Day', 'lat', 'lon'])\n",
    "    \n",
    "    fire_pws_intersection_xr = fire_pws_intersection.to_xarray()\n",
    "    \n",
    "    #load in PWS data associated with the fire (it's only one dataset)\n",
    "    \n",
    "    #open the PWS files\n",
    "    path_pws = '/data2/lthapa/PWS_6_jan_2021.nc'\n",
    "    dat_pws = xr.open_dataset(path_pws) #map is fixed in time\n",
    "    #print(dat_pws)\n",
    "    \n",
    "    dat_pws = dat_pws.assign_coords({'time': pd.to_datetime(fire_pws_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values)})\n",
    "    dat_pws_daily = dat_pws['Band1'].expand_dims({'time': pd.to_datetime(fire_pws_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values)}) #the PWS expanded over all the days\n",
    "    \n",
    "    dat_pws_daily_sub = dat_pws_daily.sel(lat = fire_pws_intersection_xr['lat'].values, \n",
    "                                          lon = fire_pws_intersection_xr['lon'].values,\n",
    "                      time = pd.to_datetime(fire_pws_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values), method='nearest')\n",
    "                                          \n",
    "    ndays = len(fire_pws_intersection_xr[str(day_start_hour)+ 'Z Start Day'])\n",
    "    \n",
    "    #preallocate space for the output\n",
    "    df_pws = pd.DataFrame({'day':np.zeros(ndays),'PWS':np.zeros(ndays)})\n",
    "\n",
    "    df_pws['day'].iloc[:] = pd.to_datetime(fire_pws_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values)\n",
    "    varis=['PWS']\n",
    "    for var in varis:\n",
    "        df_pws[var] = np.nansum(fire_pws_intersection_xr['weights'].values*dat_pws_daily_sub.values, axis=(1,2))\n",
    "    \n",
    "    return df_pws\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a3c2b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### HRRR IGBP Vegetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606282ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def hrrr_igbp_timeseries(df,day_start_hour):  \n",
    "    df_igbp = pd.DataFrame({'day': np.zeros(len(df)),'Fraction_Evergreen_Needleleaf_Forests':np.zeros(len(df)),\n",
    "                            'Fraction_Evergreen_Broadleaf_Forests':np.zeros(len(df)), \n",
    "                            'Fraction_Deciduous_Needleleaf_Forests':np.zeros(len(df)),\n",
    "                            'Fraction_Deciduous_Broadleaf_Forests':np.zeros(len(df)), \n",
    "                            'Fraction_Mixed_Forests':np.zeros(len(df)),\n",
    "                            'Fraction_Closed_Shrublands':np.zeros(len(df)),\n",
    "                            'Fraction_Open_Shrublands':np.zeros(len(df)),\n",
    "                            'Fraction_Woody_Savannas':np.zeros(len(df)),\n",
    "                            'Fraction_Savannas':np.zeros(len(df)),\n",
    "                            'Fraction_Grasslands':np.zeros(len(df)),\n",
    "                            'Fraction_Permanent_Wetlands':np.zeros(len(df)),\n",
    "                            'Fraction_Croplands':np.zeros(len(df)),\n",
    "                            'Fraction_Urban_and_Builtup_Lands':np.zeros(len(df)),\n",
    "                            'Fraction_Cropland_Natural_Vegetation_Mosaics':np.zeros(len(df)),\n",
    "                            'Fraction_Permanent_Snow_and_Ice':np.zeros(len(df)),\n",
    "                            'Fraction_Barren':np.zeros(len(df)),\n",
    "                            'Fraction_Water_Bodies':np.zeros(len(df))})\n",
    "    \n",
    "    varis = ['Evergreen Needleleaf Forests','Evergreen Broadleaf Forests', 'Deciduous Needleleaf Forests',\n",
    "         'Deciduous Broadleaf Forests','Mixed Forests','Closed Shrublands', 'Open Shrublands', 'Woody Savannas',\n",
    "         'Savannas','Grasslands', 'Permanent Wetlands','Croplands','Urban and Builtup Lands', \n",
    "         'Cropland Natural Vegetation Mosaics','Permanent Snow and Ice','Barren','Water Bodies']\n",
    "\n",
    "        \n",
    "    #do the intersection, in parallel\n",
    "    tic=time.time()\n",
    "    hrrr_intersections = Parallel(n_jobs=8)(delayed(calculate_intersection)\n",
    "                                 (fire_daily.iloc[ii:ii+1],'HRRR_GRID',0.05) \n",
    "                                 for ii in range(len(fire_daily)))\n",
    "    fire_hrrr_intersection=gpd.GeoDataFrame(pd.concat(hrrr_intersections, ignore_index=True))\n",
    "    fire_hrrr_intersection.set_geometry(col='geometry')\n",
    "    toc = time.time()\n",
    "    print(toc-tic)\n",
    "    fire_hrrr_intersection = fire_hrrr_intersection.set_index([str(day_start_hour)+ 'Z Start Day', 'row', 'col'])\n",
    "    fire_hrrr_intersection_xr = fire_hrrr_intersection.to_xarray()\n",
    "    print(fire_hrrr_intersection_xr['weights'].sum(dim=str(day_start_hour)+ 'Z Start Day'))\n",
    "    \n",
    "    #load in all the HRRR days we want\n",
    "    times = pd.date_range(np.datetime64(df[str(day_start_hour)+ 'Z Start Day'].iloc[0]),\n",
    "                        np.datetime64(df[str(day_start_hour)+ 'Z Start Day'].iloc[len(df)-1])+\n",
    "                        np.timedelta64(1,'D'))\n",
    "    files,times_used = make_file_namelist(times,'/data2/lthapa/ML_daily/pygraf/Processed_HRRR_YYYYMMDDHH.nc')\n",
    "    dat_hrrr = xr.open_mfdataset(files,concat_dim='time',combine='nested',compat='override', coords='all')\n",
    "    dat_hrrr = dat_hrrr.assign_coords({'time': times})\n",
    "\n",
    "    #select by time and location\n",
    "    hrrr_daily_mean = dat_hrrr['veggie'].resample(time='24H',base=day_start_hour, label='left').mean(dim='time') #take the daily mean        \n",
    "        \n",
    "    hrrr_daily_mean_region = hrrr_daily_mean.sel(grid_yt = np.unique(fire_hrrr_intersection_xr['row'].values),\n",
    "                                                 grid_xt = np.unique(fire_hrrr_intersection_xr['col'].values),\n",
    "                                                 time = pd.to_datetime(fire_hrrr_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values+\n",
    "                                                 'T'+str(day_start_hour)+':00:00')) #get the location of the overlaps\n",
    "    \n",
    "    \n",
    "    df_igbp['day'] = pd.to_datetime(fire_hrrr_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values+\n",
    "                                                 'T'+str(day_start_hour)+':00:00')\n",
    "    \n",
    "    weights_fire = fire_hrrr_intersection_xr['weights'].values\n",
    "    veggie_fire = hrrr_daily_mean_region.values\n",
    "    \n",
    "    for vt in range(1,18):\n",
    "        weights_by_veg_type= np.where(veggie_fire==vt,weights_fire,0)\n",
    "        #print(np.nansum(weights_by_veg_type,axis=(1,2))) #this is what we want to return\n",
    "        df_igbp['Fraction_'+varis[vt-1].replace(' ', '_')] = np.nansum(weights_by_veg_type,axis=(1,2))\n",
    "        \n",
    "    \n",
    "    \n",
    "    df_igbp_choose_max = df_igbp[['Fraction_Evergreen_Needleleaf_Forests','Fraction_Evergreen_Broadleaf_Forests', 'Fraction_Deciduous_Needleleaf_Forests',\n",
    "                            'Fraction_Deciduous_Broadleaf_Forests', 'Fraction_Mixed_Forests','Fraction_Closed_Shrublands',\n",
    "                            'Fraction_Open_Shrublands','Fraction_Woody_Savannas','Fraction_Savannas',\n",
    "                            'Fraction_Grasslands','Fraction_Permanent_Wetlands','Fraction_Croplands',\n",
    "                            'Fraction_Urban_and_Builtup_Lands','Fraction_Cropland_Natural_Vegetation_Mosaics','Fraction_Permanent_Snow_and_Ice',\n",
    "                            'Fraction_Barren','Fraction_Water_Bodies']]\n",
    "    \n",
    "    return df_igbp\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e2b41",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ESI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d50f04",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def esi_timeseries(df, day_start_hour):\n",
    "    #preallocate space for the output\n",
    "    df_esi = pd.DataFrame({'day':np.zeros(len(df)),'ESI':np.zeros(len(df))})\n",
    "    \n",
    "    #do the intersection, in parallel\n",
    "    tic=time.time()\n",
    "    esi_intersections = Parallel(n_jobs=8)(delayed(calculate_intersection)\n",
    "                                 (fire_daily.iloc[ii:ii+1],'ESI_GRID',0.05) \n",
    "                                 for ii in range(len(fire_daily)))\n",
    "    toc = time.time()\n",
    "    print(toc-tic)\n",
    "    \n",
    "    fire_esi_intersection=gpd.GeoDataFrame(pd.concat(esi_intersections, ignore_index=True))\n",
    "    fire_esi_intersection.set_geometry(col='geometry')\n",
    "    \n",
    "    \n",
    "    fire_esi_intersection = fire_esi_intersection.set_index([str(day_start_hour)+ 'Z Start Day', 'lat', 'lon'])\n",
    "    \n",
    "    fire_esi_intersection_xr = fire_esi_intersection.to_xarray()\n",
    "    print(fire_esi_intersection_xr['weights'].sum(dim=['lat','lon']))\n",
    "    \n",
    "\n",
    "    #load in esi data associated with the fire\n",
    "    times = pd.date_range(np.datetime64(df[str(day_start_hour)+ 'Z Start Day'].iloc[0]),\n",
    "                        np.datetime64(df[str(day_start_hour)+ 'Z Start Day'].iloc[len(df)-1])+\n",
    "                        np.timedelta64(1,'D'))\n",
    "    esi_filenames, esi_times = make_file_namelist(times,'/data2/lthapa/DFPPM_4WK_YYYYJJJ.nc')\n",
    "    \n",
    "    print(esi_filenames)\n",
    "    print(esi_times)\n",
    "    \n",
    "    \n",
    "    #open the esi files\n",
    "    dat_esi = xr.open_mfdataset(esi_filenames,concat_dim='time',combine='nested',compat='override', coords='all')\n",
    "    dat_esi = dat_esi.assign_coords({'time': esi_times}) #assign coords so we can resample along time\n",
    "    dat_esi = dat_esi.where(dat_esi['Band1']!=-9999)\n",
    "    dat_esi_daily = dat_esi.reindex(time=times,method='nearest')\n",
    "    dat_esi_daily_sub = dat_esi_daily.sel(lat = fire_esi_intersection_xr['lat'].values, \n",
    "                                          lon = fire_esi_intersection_xr['lon'].values,\n",
    "                      time = pd.to_datetime(fire_esi_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values), method='nearest')\n",
    "                                          \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    df_esi['day'].iloc[:] = pd.to_datetime(fire_esi_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values)\n",
    "    varis=['ESI']\n",
    "    for var in varis:\n",
    "        df_esi[var] = np.nansum(fire_esi_intersection_xr['weights'].values*dat_esi_daily_sub['Band1'].values, axis=(1,2))\n",
    "    \n",
    "    return df_esi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b441cc4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5d1177a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Resources/Personel (different format because database is excel spreadsheets, not netcdf files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281bc73b",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resources_timeseries(df, day_start_hour,sit209_data):\n",
    "\n",
    "    #get the fire incident number, lat, and lon\n",
    "    incident_number = df['Incident Number'].iloc[0]\n",
    "    fire_lat = df['Lat Fire'].iloc[0]\n",
    "    fire_lon = df['Lon Fire'].iloc[0]\n",
    "    #print(incident_number, fire_lat, fire_lon)\n",
    "    \n",
    "    sit209_data_fire = sit209_data[sit209_data['INC_IDENTIFIER']==incident_number]\n",
    "    #print(sit209_data_fire)\n",
    "    #do the time zone conversion\n",
    "    obj=TimezoneFinder() #initialize the timezone finder\n",
    "    tz = obj.timezone_at(lng=fire_lon, lat=fire_lat) #get the timezone\n",
    "    local = pytz.timezone(tz)\n",
    "    utc = pytz.utc\n",
    "    \n",
    "    #put the start and end times in local time\n",
    "    loc_dt_start = [local.localize(datetime.strptime(date, '%m/%d/%Y %H:%M:%S %p')) for date in sit209_data_fire['REPORT_FROM_DATE'].values]\n",
    "    loc_dt_end = [local.localize(datetime.strptime(date, '%m/%d/%Y %H:%M:%S %p')) for date in sit209_data_fire['REPORT_TO_DATE'].values]\n",
    "    \n",
    "    #put them in UTC time\n",
    "    utc_dt_start = [time_start.astimezone(utc) for time_start in loc_dt_start]\n",
    "    utc_dt_end = [time_end.astimezone(utc) for time_end in loc_dt_end]\n",
    "    \n",
    "    start_day = pd.to_datetime(utc_dt_start[0]).strftime('%Y-%m-%d')+' '+str(day_start_hour)+':00'\n",
    "    \n",
    "    \n",
    "    #reassign to UTC time, this DOES keep track of daylight savings (eg +7 is used for PDT, +8 is used for PST)\n",
    "    sit209_data_fire['Report Start UTC'] = pd.to_datetime(utc_dt_start)\n",
    "    sit209_data_fire['Report End UTC'] = pd.to_datetime(utc_dt_end)\n",
    "    sit209_data_fire['Timezone']= tz\n",
    "    \n",
    "    #localise the index\n",
    "    sit209_data_fire = sit209_data_fire.set_index(['Report Start UTC']).tz_localize(None)\n",
    "    #print(sit209_data_fire.iloc[0:4])\n",
    "    \n",
    "    \n",
    "    ## do the 12z-12z day grouping, based on the UTC times\n",
    "    #start_day_utc = str(utc_dt_start[0])\n",
    "    start_day_utc=str(df[str(day_start_hour)+'Z Start Day'][0])\n",
    "    start_datetime_utc = np.datetime64(start_day_utc[0:10]+'T'+str(day_start_hour).zfill(2)+':00')\n",
    "    print(start_datetime_utc)\n",
    "    #sit209_data_fire = sit209_data_fire.resample('24H',origin=start_datetime_utc)\n",
    "\n",
    "    personnel = sit209_data_fire['RESOURCE_PERSONNEL'].resample('24H',origin=start_datetime_utc).sum().reset_index()\n",
    "    percent_contained = sit209_data_fire['PCT_CONTAINED_COMPLETED'].resample('24H',origin=start_datetime_utc).mean().reset_index()\n",
    "    df_sit209 = pd.concat([percent_contained,personnel.drop(columns='Report Start UTC')],axis=1)\n",
    "    df_sit209.columns=['day', 'percent_contained', 'personnel']\n",
    "    df_sit209['day'] = pd.to_datetime(df_sit209['day'].values).strftime('%Y-%m-%d')\n",
    "    inds = df_sit209['day'].isin(df[str(day_start_hour)+'Z Start Day']).values\n",
    "    \n",
    "    return df_sit209[inds]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91e8fc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fuel Loading (1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47ceb580",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fuel_loading_timeseries(df, day_start_hour):\n",
    "    #do the intersection, in parallel\n",
    "    tic = time.time()\n",
    "    fuel_loading_intersections = Parallel(n_jobs=8)(delayed(calculate_intersection)\n",
    "                                 (fire_daily.iloc[ii:ii+1],'FUEL_LOADING_GRID',0.05) \n",
    "                                 for ii in range(len(fire_daily)))\n",
    "    toc = time.time()\n",
    "    print(toc-tic)\n",
    "    \n",
    "    fire_fuel_loading_intersection=gpd.GeoDataFrame(pd.concat(fuel_loading_intersections, ignore_index=True))\n",
    "    fire_fuel_loading_intersection.set_geometry(col='geometry')\n",
    "    fire_fuel_loading_intersection = fire_fuel_loading_intersection.set_index([str(day_start_hour)+ 'Z Start Day', 'lat', 'lon'])\n",
    "    \n",
    "    fire_fuel_loading_intersection_xr = fire_fuel_loading_intersection.to_xarray()\n",
    "    \n",
    "    #load in fuel load data associated with the fire (it's only one dataset)\n",
    "    \n",
    "    #open the fuel loading file\n",
    "    path_fuel_loading = '/data/lthapa/GSL_Internship/fuel_loading_FCCS16.nc'\n",
    "    dat_fuel_loading = xr.open_dataset(path_fuel_loading) #map is fixed in time\n",
    "    \n",
    "    \n",
    "    dat_fuel_loading = dat_fuel_loading.assign_coords({'time': pd.to_datetime(fire_fuel_loading_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values)})\n",
    "    dat_fuel_loading = dat_fuel_loading.where(dat_fuel_loading['fuel_loadings']!=-9999)    \n",
    "    dat_fuel_loading_daily = dat_fuel_loading['fuel_loadings'].expand_dims({'time': pd.to_datetime(fire_fuel_loading_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values)}) #the PWS expanded over all the days\n",
    "    \n",
    "    dat_fuel_loading_daily_sub = dat_fuel_loading_daily.sel(lat = fire_fuel_loading_intersection_xr['lat'].values, \n",
    "                                          lon = fire_fuel_loading_intersection_xr['lon'].values,\n",
    "                      time = pd.to_datetime(fire_fuel_loading_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values), method='nearest')\n",
    "                                          \n",
    "    ndays = len(fire_fuel_loading_intersection_xr[str(day_start_hour)+ 'Z Start Day'])\n",
    "    \n",
    "    #preallocate space for the output\n",
    "    df_fuel_loading = pd.DataFrame({'day':np.zeros(ndays),'fuel_loadings':np.zeros(ndays)})\n",
    "\n",
    "    df_fuel_loading['day'].iloc[:] = pd.to_datetime(fire_fuel_loading_intersection_xr[str(day_start_hour)+ 'Z Start Day'].values)\n",
    "    varis=['fuel_loadings']\n",
    "    for var in varis:\n",
    "        df_fuel_loading[var] = np.nansum(fire_fuel_loading_intersection_xr['weights'].values*dat_fuel_loading_daily_sub.values, axis=(1,2))\n",
    "    \n",
    "    return df_fuel_loading\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e873cee3",
   "metadata": {},
   "source": [
    "### Fire Area (ha and ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ee35300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire_area_timeseries(df,day_start_hour):\n",
    "    df_fire_area = df[[str(start_time)+'Z Start Day','fire area (ha)']].rename(columns={str(start_time)+'Z Start Day':'day'})\n",
    "    df_fire_area['fire area (m2)'] = df_fire_area['fire area (ha)']*10000\n",
    "    df_fire_area['fire area (acre)'] = df_fire_area['fire area (ha)']*2.471\n",
    "    return df_fire_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce84a517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2428075a",
   "metadata": {},
   "source": [
    "## Dataset-Independent Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409b36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes and saves a geodataframe of a grid given the center and corner points for that grid as 2D matrices\n",
    "def build_one_gridcell(LAT_COR, LON_COR, LAT_CTR, LON_CTR, loc):\n",
    "    #print(ii,jj,count)\n",
    "    ii=loc[0]\n",
    "    jj=loc[1]\n",
    "    #print(LAT_CTR[ii,jj], LON_CTR[ii,jj]) #ctr\n",
    "    sw = (LON_COR[ii, jj],LAT_COR[ii, jj]) #SW\n",
    "    se =(LON_COR[ii, jj+1],LAT_COR[ii, jj+1]) #SE\n",
    "    nw = (LON_COR[ii+1, jj],LAT_COR[ii+1, jj]) #NW\n",
    "    ne = (LON_COR[ii+1, jj+1],LAT_COR[ii+1, jj+1]) #NE\n",
    "            \n",
    "    poly_cell = Polygon([sw,nw,ne,se])\n",
    "    \n",
    "    return LAT_CTR[ii,jj], LON_CTR[ii,jj],ii,jj,poly_cell\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15123fe8",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#poly is the polygon for one timestep (in lcc)\n",
    "#grid is an xarray of a model grid from the nc file\n",
    "#grid_names is a string array [0:'lat_center_name',1:'lon_center_name',2:'lat_corner_name',3:'lon_corner_name']\n",
    "\n",
    "def calculate_intersection(poly,dataset_name,bf):\n",
    "    #load in the merra grid\n",
    "    grid = xr.open_dataset(dataset_name+'.nc')\n",
    "\n",
    "    #get the bounds of the buffered polygons\n",
    "    poly_latlon =poly.to_crs(epsg=4326)\n",
    "    bounds = poly_latlon.buffer(bf).bounds\n",
    "    \n",
    "    #first check for rows and cols\n",
    "    [rows,cols] = np.where((grid.LAT_CTR.values>bounds['miny'].values)&\n",
    "                    (grid.LAT_CTR.values<bounds['maxy'].values)&\n",
    "                    (grid.LON_CTR.values>bounds['minx'].values)&\n",
    "                    (grid.LON_CTR.values<bounds['maxx'].values))\n",
    "    #print(rows,cols)\n",
    "    \n",
    "    locs = zip(rows,cols)\n",
    "    #print([loc for loc in locs])\n",
    "    \n",
    "    \"\"\"\n",
    "    if (rows.size==0)|(cols.size==0):\n",
    "        lat_middle = (bounds['maxy'].values+bounds['miny'].values)/2\n",
    "        lon_middle = (bounds['maxx'].values+bounds['minx'].values)/2\n",
    "        \n",
    "        distance = np.sqrt((grid.LAT_CTR.values-lat_middle)**2+(grid.LON_CTR.values-lon_middle)**2)\n",
    "        row_minloc,col_minloc = np.where(distance==np.min(distance))\n",
    "        print(row_minloc,col_minloc)\n",
    "        \n",
    "        rows = np.arange(row_minloc-1,row_minloc+2,1)\n",
    "        cols = np.arange(col_minloc-1,col_minloc+2,1)\n",
    "        \n",
    "        locs = [(row,col) for row in rows for col in cols]\n",
    "        \n",
    "    #print(rows,cols)\n",
    "    #print(locs)\n",
    "    \"\"\"\n",
    "    \n",
    "    #make a geodataframe (in paralell of the rows and cols)\n",
    "    results = Parallel(n_jobs=8)(delayed(build_one_gridcell)\n",
    "                                 (grid['LAT_COR'].values, grid['LON_COR'].values,\n",
    "                                  grid['LAT_CTR'].values, grid['LON_CTR'].values,loc) \n",
    "                                 for loc in locs)\n",
    "\n",
    "    #format the grid subset into a dataframs\n",
    "    df_grid=gpd.GeoDataFrame(results)\n",
    "    df_grid.columns = ['lat', 'lon', 'row', 'col', 'geometry']\n",
    "    df_grid.set_geometry(col='geometry',inplace=True,crs='EPSG:4326') #need to say it's in lat/lon before transform to LCC\n",
    "    df_grid=df_grid.to_crs(epsg=3347)\n",
    "    \n",
    "    #intersect the polygon with the grid subset\n",
    "    intersection = gpd.overlay(df_grid, poly, how='intersection',keep_geom_type=False).drop_duplicates()\n",
    "    intersection['grid intersection area (ha)'] =intersection['geometry'].area/10000\n",
    "    intersection['weights'] = intersection['grid intersection area (ha)']/intersection['fire area (ha)'] \n",
    "    \n",
    "    return intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba2e5351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file_namelist(time,base_filename):\n",
    "    filename_list = np.array([])\n",
    "    times_back_used = np.array([])\n",
    "    for jj in range(len(time)):\n",
    "        fname = base_filename.replace('YYYY',time[jj].strftime('%Y')).\\\n",
    "                                replace('MM',time[jj].strftime('%m')).\\\n",
    "                                replace('DD',time[jj].strftime('%d')).\\\n",
    "                                replace('HH',time[jj].strftime('%H')).\\\n",
    "                                replace('JJJ',time[jj].strftime('%j'))\n",
    "        if exists(fname):\n",
    "            filename_list = np.append(filename_list,fname)\n",
    "            times_back_used = np.append(times_back_used,time[jj])\n",
    "    return filename_list, times_back_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d455e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8c0038b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Check that the buffers work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83022d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#all fires\n",
    "#fire_incidents = ['BOBCAT', 'DOLAN', 'HOLIDAY FARM','CREEK', 'LAKE', 'CAMERON PEAK', 'PINE GULCH', 'WILLIAMS FLATS', 'SHADY','PEDRO MOUNTAIN', 'WALKER', '204 COW']\n",
    "\n",
    "#2020 fires\n",
    "#fire_incidents = ['AUGUST COMPLEX','BOBCAT', 'DOLAN', 'HOLIDAY FARM','CREEK', 'LAKE', 'CAMERON PEAK', 'PINE GULCH']\n",
    "#fire_incidents=['BOBCAT', 'DOLAN', 'HOLIDAY FARM','CREEK', 'LAKE', 'CAMERON PEAK', 'PINE GULCH']\n",
    "fire_incidents = ['LAKE']\n",
    "\n",
    "path_poly = '/data2/lthapa/ML_daily/fire_polygons/'\n",
    "suffix_poly = 'Z_day_start.geojson'\n",
    "start_time=12\n",
    "for jj in range(len(fire_incidents)):\n",
    "    fire_name = fire_incidents[jj].lower().replace(' ','_')\n",
    "    print(path_poly+fire_name+'_VIIRS_daily_'+str(start_time)+suffix_poly)\n",
    "    fire_daily = gpd.read_file(path_poly+fire_name+'_VIIRS_daily_'+str(start_time)+suffix_poly)\n",
    "    fire_daily=fire_daily.drop(columns=['Current Overpass'])\n",
    "    fire_daily = fire_daily.drop(np.where(fire_daily['geometry']==None)[0])\n",
    "    fire_daily['fire area (ha)'] = fire_daily['geometry'].area/10000 #hectares\n",
    "    fire_daily.set_geometry(col='geometry', inplace=True) #designate the geometry column\n",
    "    fire_daily = fire_daily.rename(columns={'Current Day':'UTC Day', 'Local Day': str(start_time)+ 'Z Start Day'})\n",
    "    \n",
    "    fire_daily = fire_daily.iloc[np.array(fire_daily['UTC Day'].values,dtype='datetime64')<=np.datetime64('2020-10-31'),:]\n",
    "\n",
    "    #print(fire_daily)\n",
    "    \n",
    "    #merra\n",
    "    tic = time.time()\n",
    "    merra_intersections = Parallel(n_jobs=8)(delayed(calculate_intersection)\n",
    "                                 (fire_daily.iloc[ii:ii+1],'ESI_GRID',0.05) \n",
    "                                 for ii in range(len(fire_daily)))\n",
    "    toc = time.time()\n",
    "    print(toc-tic)\n",
    "    fire_merra_intersection=gpd.GeoDataFrame(pd.concat(merra_intersections, ignore_index=True))\n",
    "    fire_merra_intersection.set_geometry(col='geometry')\n",
    "    fire_merra_intersection = fire_merra_intersection.set_index([str(start_time)+ 'Z Start Day', 'lat', 'lon'])\n",
    "    print(fire_merra_intersection)\n",
    "    fire_merra_intersection_xr = fire_merra_intersection.to_xarray()\n",
    "    print(fire_merra_intersection_xr['weights'].sum(dim=['lat','lon']).values)\n",
    "    \n",
    "\n",
    "    esi_intersections = Parallel(n_jobs=8)(delayed(calculate_intersection)\n",
    "                                 (fire_daily.iloc[ii:ii+1],'ESI_GRID',0.05) \n",
    "                                 for ii in range(len(fire_daily)))\n",
    "    toc = time.time()\n",
    "    fire_esi_intersection=gpd.GeoDataFrame(pd.concat(esi_intersections, ignore_index=True))\n",
    "    fire_esi_intersection.set_geometry(col='geometry')\n",
    "    fire_esi_intersection = fire_esi_intersection.set_index([str(start_time)+ 'Z Start Day', 'lat', 'lon'])\n",
    "    fire_esi_intersection_xr = fire_esi_intersection.to_xarray()\n",
    "    print(fire_esi_intersection_xr['weights'].sum(dim=['lat','lon']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485844d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46247021",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start_time=12\n",
    "fire_daily = gpd.read_file('./fire_polygons/cameron_peak_VIIRS_daily_12Z_day_start.geojson')\n",
    "#fire_daily = gpd.read_file('./fire_polygons/august_complex_VIIRS_daily_12Z_day_start.geojson')\n",
    "#fire_daily = gpd.read_file('./fire_polygons/williams_flats_VIIRS_daily_12Z_day_start.geojson')\n",
    "fire_daily=fire_daily.drop(columns=['Current Overpass'])\n",
    "fire_daily = fire_daily.drop(np.where(fire_daily['geometry']==None)[0])\n",
    "fire_daily['fire area (ha)'] = fire_daily['geometry'].area/10000 #hectares\n",
    "fire_daily.set_geometry(col='geometry', inplace=True) #designate the geometry column\n",
    "fire_daily = fire_daily.rename(columns={'Current Day':'UTC Day', 'Local Day': str(start_time)+ 'Z Start Day'})\n",
    "fire_daily = fire_daily.iloc[np.array(fire_daily['UTC Day'].values,dtype='datetime64')<=np.datetime64('2020-10-31'),:]\n",
    "print(fire_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748daf3",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#hrrr_timeseries(fire_daily.iloc[15:25],12)\n",
    "\n",
    "times_intersect = np.unique(fire_daily[str(12)+ 'Z Start Day'].iloc[39:40].values)\n",
    "for today in times_intersect:\n",
    "    print(today)\n",
    "    times_back = pd.date_range(start=np.datetime64(today)-np.timedelta64(5,'D'), end=np.datetime64(today)+\n",
    "                                   np.timedelta64(1,'D'),freq='H')\n",
    "    files_back,times_back_used = make_hrrr_file_namelist(times_back)\n",
    "    \n",
    "    #print(files_back)\n",
    "    dat_hrrr = xr.open_mfdataset(files_back,concat_dim='time',combine='nested',compat='override', coords='all')\n",
    "    dat_hrrr = dat_hrrr.assign_coords({'time': times_back_used})\n",
    "    hrrr_daily_mean = dat_hrrr.resample(time='24H',base=12, label='left').mean(dim='time') #take the daily mean        \n",
    "\n",
    "    print(hrrr_daily_mean.time)\n",
    "    dat_hrrr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b93d1",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ints = calculate_intersection(fire_daily.iloc[11:12],'ESI_GRID',0.05)\n",
    "print(ints.sum())\n",
    "#tic = time.time()\n",
    "#hrrr_intersections = Parallel(n_jobs=8)(delayed(calculate_intersection)\n",
    "#                                 (fire_daily.iloc[ii:ii+1],'HRRR_GRID',0.01) \n",
    "#                                 for ii in range(len(fire_daily)))\n",
    "#toc=time.time()\n",
    "#print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cee4b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid = xr.open_dataset('PWS_GRID.nc')\n",
    "print(grid.LAT_CTR[0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7369928",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = xr.open_dataset('HRRR_GRID.nc')\n",
    "bf = 0.05\n",
    "\n",
    "for ii in range(len(fire_daily)):\n",
    "    poly=fire_daily[ii:ii+1]\n",
    "    #get the bounds of the buffered polygons\n",
    "    poly_latlon =poly.to_crs(epsg=4326)\n",
    "    bounds = poly_latlon.buffer(bf).bounds\n",
    "    \n",
    "    #first check for rows and cols\n",
    "    [rows,cols] = np.where((grid.LAT_CTR.values>bounds['miny'].values)&\n",
    "                    (grid.LAT_CTR.values<bounds['maxy'].values)&\n",
    "                    (grid.LON_CTR.values>bounds['minx'].values)&\n",
    "                    (grid.LON_CTR.values<bounds['maxx'].values))\n",
    "    print(rows,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2bd8b",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4e8f5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
