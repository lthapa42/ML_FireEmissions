{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5247efd6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b74c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import path\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "np.set_printoptions(threshold=100000)\n",
    "from shapely.geometry import Polygon, Point, MultiPoint\n",
    "from shapely.ops import cascaded_union, unary_union, transform\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import shapely.wkt\n",
    "from shapely.validation import explain_validity,make_valid\n",
    "import xarray as xr\n",
    "import pygeos as pg\n",
    "import time\n",
    "import seaborn as sns\n",
    "from my_functions import sat_vap_press, vap_press, hot_dry_windy, haines\n",
    "\n",
    "from timezonefinder import TimezoneFinder\n",
    "import pytz\n",
    "import time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "from os.path import exists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4d3fb",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66730cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_merra_file_namelist(time):\n",
    "    base_filename = '/data2/lthapa/YEAR/MERRA2/WESTUS_MERRA2_400.inst1_2d_lfo_Nx.FULLDATE.nc4'\n",
    "    base_filename_list = np.repeat(base_filename, len(time))\n",
    "\n",
    "    \n",
    "    for jj in range(len(time)):\n",
    "        base_filename_list[jj] = base_filename_list[jj].replace('YEAR',time[jj].strftime('%Y')).\\\n",
    "                                    replace('FULLDATE',time[jj].strftime('%Y%m%d'))\n",
    "        if (time[jj].strftime('%Y%m')=='202009'):\n",
    "            base_filename_list[jj] = base_filename_list[jj].replace('400','401')\n",
    "    return base_filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merra_timeseries(df,day_start_hour):\n",
    "    df_merra = pd.DataFrame({'day': np.zeros(len(df)),'temp':np.zeros(len(df)), 'vpd':np.zeros(len(df)), \n",
    "                             'wind':np.zeros(len(df)),'hd0w0':np.zeros(len(df)), 'hd1w0':np.zeros(len(df)),\n",
    "                             'hd2w0':np.zeros(len(df)),'hd3w0':np.zeros(len(df)), 'hd4w0':np.zeros(len(df)),\n",
    "                             'hd5w0':np.zeros(len(df))})\n",
    "    #load in the grid\n",
    "    merra_grid = gpd.read_file('MERRA_GRID.geojson')\n",
    "    merra_grid = merra_grid.to_crs(epsg=3347) #put into lambert conformal conic \n",
    "    \n",
    "    #do the intersection, not with a for loop!\n",
    "    fire_merra_intersection = gpd.overlay(df, merra_grid, how='intersection',keep_geom_type=False)\n",
    "    fire_merra_intersection['grid intersection area (ha)'] =fire_merra_intersection['geometry'].area/10000\n",
    "    fire_merra_intersection['weights'] = fire_merra_intersection['grid intersection area (ha)']/fire_merra_intersection['fire area (ha)'] \n",
    "    \n",
    "    \n",
    "    #loop over all of the days we have intersections\n",
    "    times_intersect = np.unique(fire_merra_intersection[str(day_start_hour)+ 'Z Start Day'].values)\n",
    "    times_utc = np.unique(fire_merra_intersection['UTC Day'].values)\n",
    "    \n",
    "    count = 0\n",
    "    for today in times_intersect:\n",
    "        print(type(today))\n",
    "        print(np.datetime64(today+ ' '+str(day_start_hour)+':00:00'))\n",
    "        #get the time\n",
    "        df_sub = fire_merra_intersection.iloc[np.where(fire_merra_intersection[str(day_start_hour)+ 'Z Start Day'].values==today)]\n",
    "        df_sub = df_sub.set_index([str(day_start_hour)+ 'Z Start Day', 'lat', 'lon'])\n",
    "        intersection_sub = df_sub.to_xarray() #polygon and weights for today\n",
    "\n",
    "        times_back = pd.date_range(start=np.datetime64(today)-np.timedelta64(5,'D'), end=np.datetime64(today)+np.timedelta64(1,'D'))\n",
    "        print(times_back)\n",
    "        files_back = make_merra_file_namelist(times_back)\n",
    "        \n",
    "        #load in all the merra files associated with this lookback window\n",
    "        dat_merra = xr.open_mfdataset(files_back,concat_dim='time',combine='nested',compat='override', coords='all')\n",
    "    \n",
    "        #add the derived data (svp, vp, vpd)\n",
    "        dat_merra=dat_merra.assign(ESAT=sat_vap_press(dat_merra.TLML))\n",
    "        dat_merra=dat_merra.assign(E=vap_press(dat_merra.QLML, dat_merra.TLML))\n",
    "        dat_merra=dat_merra.assign(VPD=dat_merra.ESAT-dat_merra.E)\n",
    "        \n",
    "        merra_daily_mean = dat_merra.resample(time='24H',base=day_start_hour, label='left').mean(dim='time') #take the daily mean        \n",
    "        merra_daily_mean_region = merra_daily_mean.sel(lat = np.unique(intersection_sub['lat'].values),\n",
    "                                  lon = np.unique(intersection_sub['lon'].values)) #get the location of the overlaps\n",
    "        \n",
    "        hd0 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        hd1 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(1,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd2 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(2,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd3 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(3,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd4 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(4,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        hd5 = np.nansum((merra_daily_mean_region['VPD'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')-np.timedelta64(5,'D')).values)*\n",
    "                     (intersection_sub['weights'].values))\n",
    "        w = np.nansum((merra_daily_mean_region['SPEEDLML'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        t = np.nansum((merra_daily_mean_region['TLML'].sel(time=np.datetime64(today+ ' '+str(day_start_hour)+':00:00')).values)*(intersection_sub['weights'].values))\n",
    "        \n",
    "        df_merra.iloc[count,:] = [today+ ' '+str(day_start_hour)+':00:00',t,hd0,w,hd0*w,hd1*w,hd2*w,hd3*w,hd4*w,hd5*w]\n",
    "        dat_merra.close()\n",
    "        count =count+1\n",
    "    return df_merra\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f64249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all fires\n",
    "#fire_incidents = ['BOBCAT', 'DOLAN', 'HOLIDAY FARM','CREEK', 'LAKE', 'CAMERON PEAK', 'PINE GULCH', 'WILLIAMS FLATS', 'SHADY','PEDRO MOUNTAIN', 'WALKER', '204 COW']\n",
    "\n",
    "#2020 fires\n",
    "#fire_incidents = ['AUGUST COMPLEX','BOBCAT', 'DOLAN', 'HOLIDAY FARM','CREEK', 'LAKE', 'CAMERON PEAK', 'PINE GULCH']\n",
    "fire_incidents = ['LAKE']\n",
    "start_time = 12\n",
    "path_poly = '/data2/lthapa/ML_daily/fire_polygons/'\n",
    "for jj in range(len(fire_incidents)):\n",
    "    \n",
    "    print(fire_incidents[jj])\n",
    "    fire_daily = gpd.read_file(path_poly+fire_incidents[jj].lower().replace(' ', '_')+'_VIIRS_daily_'+str(start_time)+'Z_day_start.geojson') #polygons and attributes\n",
    "    \n",
    "    #get rid of rows/cols we don't need\n",
    "    fire_daily=fire_daily.drop(columns=['Current Overpass'])\n",
    "    fire_daily = fire_daily.drop(np.where(fire_daily['geometry']==None)[0])\n",
    "    fire_daily['fire area (ha)'] = fire_daily['geometry'].area/10000 #hectares\n",
    "    fire_daily.set_geometry(col='geometry', inplace=True) #designate the geometry column\n",
    "    fire_daily = fire_daily.rename(columns={'Current Day':'UTC Day', 'Local Day': str(start_time)+ 'Z Start Day'})\n",
    "    \n",
    "    #merra\n",
    "    me = merra_timeseries(fire_daily,12)\n",
    "    print(me)\n",
    "    #me.to_csv('./fire_features/'+fire_incidents[jj].lower().replace(' ', '_')+'_Daily_MERRA_Moving_Average_2.csv') #daily averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d688aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3ae16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f4162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845bd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64317a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_back = pd.date_range(start=np.datetime64('2020-08-12'), freq='H', periods=24*2)\n",
    "print(times_back)\n",
    "\n",
    "\n",
    "ds = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        test=([ \"time\"], np.linspace(0,len(times_back)),\n",
    "    ),\n",
    "    coords=dict(\n",
    "        time=times_back,\n",
    "    )\n",
    "    ))\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eec14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df3ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiprocessing.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_daily = gpd.read_file('./fire_polygons/lake_VIIRS_daily.geojson')\n",
    "fire_daily_latlon = fire_daily.to_crs(epsg=4326)\n",
    "\n",
    "#load in the merra grid\n",
    "merra_grid = xr.open_dataset('RAVE_GRID.nc')\n",
    "\n",
    "\n",
    "#for each fire_daily polygon\n",
    "for ii in range(1):#len(fire_daily)):\n",
    "    #get the bounds\n",
    "    bounds = fire_daily_latlon['geometry'].iloc[ii].bounds\n",
    "    print(bounds)\n",
    "    [rows,cols] = np.where((merra_grid.LAT_CTR>bounds[1])&\n",
    "                    (merra_grid.LAT_CTR<bounds[3])&\n",
    "                    (merra_grid.LON_CTR>bounds[0])&\n",
    "                    (merra_grid.LON_CTR<bounds[2]))\n",
    "    #print(rows,cols)\n",
    "    \n",
    "    if rows.size==0:\n",
    "        print('empty!')\n",
    "        lat_middle = (bounds[1]+bounds[3])/2\n",
    "        lon_middle = (bounds[0]+bounds[2])/2\n",
    "\n",
    "        distance = np.sqrt((merra_grid.LAT_CTR-lat_middle)**2+(merra_grid.LON_CTR-lon_middle)**2)\n",
    "        row_min_location,col_min_location = np.where(distance ==np.min(distance))\n",
    "        rows = np.append(rows,row_min_location)\n",
    "        cols = np.append(cols,col_min_location)\n",
    "    \n",
    "    rows=np.arange(rows[0]-1,rows[len(rows)-1]+2,1)\n",
    "    cols=np.arange(cols[0]-1,cols[len(cols)-1]+2,1)\n",
    "\n",
    "    print(rows,cols)\n",
    "    \n",
    "    #make a geodataframe (in paralell of the rows and cols)\n",
    "    tic = time.time()\n",
    "    results = Parallel(n_jobs=6)(delayed(build_one_gridcell)\n",
    "                                 (merra_grid['LAT_COR'].values, merra_grid['LON_COR'].values,\n",
    "                                  merra_grid['LAT_CTR'].values, merra_grid['LON_CTR'].values,i,j) \n",
    "                                 for i in rows for j in cols)\n",
    "    toc = time.time()\n",
    "    print(toc-tic)\n",
    "    df_grid=gpd.GeoDataFrame(results)\n",
    "    df_grid.columns = ['lat', 'lon', 'row', 'col', 'geometry']\n",
    "    df_grid.set_geometry(col='geometry',inplace=True,crs='EPSG:4326') #need to say it's in lat/lon before transform to LCC\n",
    "    df_grid=df_grid.to_crs(epsg=3347)\n",
    "    #print(df_grid)\n",
    "    \n",
    "    fire_today = gpd.GeoDataFrame(fire_daily.iloc[ii:ii+1,:])\n",
    "    fire_today.set_geometry(col='geometry',inplace=True)\n",
    "    #print(fire_today)\n",
    "    \n",
    "    #intersect the polygon with the grid subset\n",
    "    print(gpd.overlay(fire_today, df_grid, how='intersection',keep_geom_type=False))\n",
    "    \n",
    "    \n",
    "#make the geodataframe\n",
    "#do the intersection\n",
    "\n",
    "merra_grid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6030414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes and saves a geodataframe of a grid given the center and corner points for that grid as 2D matrices\n",
    "def build_one_gridcell(LAT_COR, LON_COR, LAT_CTR, LON_CTR, ii,jj):\n",
    "    #print(ii,jj,count)\n",
    "    #print(LAT_CTR[ii,jj], LON_CTR[ii,jj]) #ctr\n",
    "    sw = (LON_COR[ii, jj],LAT_COR[ii, jj]) #SW\n",
    "    se =(LON_COR[ii, jj+1],LAT_COR[ii, jj+1]) #SE\n",
    "    nw = (LON_COR[ii+1, jj],LAT_COR[ii+1, jj]) #NW\n",
    "    ne = (LON_COR[ii+1, jj+1],LAT_COR[ii+1, jj+1]) #NE\n",
    "            \n",
    "    poly_cell = Polygon([sw,nw,ne,se])\n",
    "    \n",
    "    return LAT_CTR[ii,jj], LON_CTR[ii,jj],ii,jj,poly_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e9e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_today = gpd.GeoDataFrame(fire_daily.iloc[0:1,:])\n",
    "print(fire_today)\n",
    "print(df_grid)\n",
    "print(gpd.overlay(fire_today,df_grid, how='intersection',keep_geom_type=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f69b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc3e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7032c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44536d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file_namelist(time,base_filename):\n",
    "    filename_list = np.array([])\n",
    "    times_back_used = np.array([])\n",
    "    for jj in range(len(time)):\n",
    "        fname = base_filename.replace('YYYY',time[jj].strftime('%Y')).\\\n",
    "                                replace('MM',time[jj].strftime('%m')).\\\n",
    "                                replace('DD',time[jj].strftime('%d')).\\\n",
    "                                replace('HH',time[jj].strftime('%H'))\n",
    "        if exists(fname):\n",
    "            filename_list = np.append(filename_list,fname)\n",
    "            times_back_used = np.append(times_back_used,time[jj])\n",
    "    return filename_list, times_back_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range(start=np.datetime64('2020-09-10')-np.timedelta64(5,'D'), end=np.datetime64('2020-09-10')+\n",
    "                                   np.timedelta64(1,'D'),freq='D')\n",
    "print(times)\n",
    "\n",
    "print(times[0].strftime('%Y%m%d%H'))\n",
    "\n",
    "\n",
    "\n",
    "base_filename_hrrr = '/data2/lthapa/ML_daily/pygraf/Processed_HRRR_YYYYMMDDHH.nc'\n",
    "base_filename_rave = '/data2/lthapa/YYYY/AprYYYY_to_OctYYYY/Hourly_Emissions_FV3_13km_YYYYMMDD0000_YYYYMMDD2300xr.nc'\n",
    "base_filename_merra = '/data2/lthapa/YYYY/MERRA2/WESTUS_MERRA2_400.inst1_2d_lfo_Nx.YYYYMMDD.nc4'\n",
    "\n",
    "\n",
    "#make_file_namelist(times,base_filename_hrrr)\n",
    "#make_file_namelist(times,base_filename_rave)\n",
    "make_file_namelist(times,base_filename_merra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9409ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'hello'\n",
    "print(string)\n",
    "\n",
    "replaced = string.replace('j','q')\n",
    "print(replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = pd.read_excel('../Query2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185efdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q.iloc[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb04c4",
   "metadata": {},
   "source": [
    "# Building the code to get sit-209 data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1345313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INC209R_IDENTIFIER  INCIDENT_NAME      REPORT_FROM_DATE  \\\n",
      "0            11683718  Dogwood Trail  1/8/2020 12:30:00 PM   \n",
      "1            11683718  Dogwood Trail  1/8/2020 12:30:00 PM   \n",
      "2            11683732  Dogwood Trail  1/9/2020 12:30:00 PM   \n",
      "3            11683732  Dogwood Trail  1/9/2020 12:30:00 PM   \n",
      "\n",
      "         REPORT_TO_DATE  RESTYP_IDENTIFIER  RESOURCE_QUANTITY  \\\n",
      "0   1/8/2020 9:15:00 PM            9429934                2.0   \n",
      "1   1/8/2020 9:15:00 PM            9429953                NaN   \n",
      "2  1/10/2020 8:15:00 AM            9429928                2.0   \n",
      "3  1/10/2020 8:15:00 AM            9429934                2.0   \n",
      "\n",
      "   RESOURCE_PERSONNEL       CODE_NAME  INC_IDENTIFIER  PCT_CONTAINED_COMPLETED  \n",
      "0                   2  Engine, Type 6        11683717                     90.0  \n",
      "1                   0        Overhead        11683717                     90.0  \n",
      "2                   2           Dozer        11683717                     96.0  \n",
      "3                   2  Engine, Type 6        11683717                     96.0  \n"
     ]
    }
   ],
   "source": [
    "sit209_data=pd.read_csv('../Query2.txt')\n",
    "sit209_data.columns = ['INC209R_IDENTIFIER','INCIDENT_NAME','REPORT_FROM_DATE','REPORT_TO_DATE',\n",
    "              'RESTYP_IDENTIFIER', 'RESOURCE_QUANTITY','RESOURCE_PERSONNEL','CODE_NAME',\n",
    "              'INC_IDENTIFIER','PCT_CONTAINED_COMPLETED'] \n",
    "print(sit209_data.iloc[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9ff2242",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/lthapa/ML_daily/fire_polygons/lake_VIIRS_daily_12Z_day_start.geojson\n",
      "11773470.0 34.6786111 -118.4519444\n",
      "[ True  True  True  True  True  True  True  True  True  True  True False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "           day  percent_contained  personnel\n",
      "0   2020-08-12           0.000000       1576\n",
      "1   2020-08-13           5.930233       3377\n",
      "2   2020-08-14          12.000000       5444\n",
      "3   2020-08-15          12.000000       3060\n",
      "4   2020-08-16          21.630137       3784\n",
      "5   2020-08-17          38.000000       4051\n",
      "6   2020-08-18          38.000000       3808\n",
      "7   2020-08-19          41.929412       4015\n",
      "8   2020-08-20          52.000000       3686\n",
      "9   2020-08-21          52.000000       3534\n",
      "10  2020-08-22          52.000000       3666\n",
      "17  2020-08-29          90.000000        370\n",
      "   12Z Start Day  Incident Number Fire Name     UTC Day   Lat Fire  \\\n",
      "0     2020-08-12       11773470.0      LAKE  2020-08-13  34.678611   \n",
      "1     2020-08-13       11773470.0      LAKE  2020-08-14  34.678611   \n",
      "2     2020-08-14       11773470.0      LAKE  2020-08-15  34.678611   \n",
      "3     2020-08-15       11773470.0      LAKE  2020-08-16  34.678611   \n",
      "4     2020-08-16       11773470.0      LAKE  2020-08-17  34.678611   \n",
      "5     2020-08-17       11773470.0      LAKE  2020-08-18  34.678611   \n",
      "6     2020-08-18       11773470.0      LAKE  2020-08-19  34.678611   \n",
      "7     2020-08-19       11773470.0      LAKE  2020-08-20  34.678611   \n",
      "8     2020-08-20       11773470.0      LAKE  2020-08-21  34.678611   \n",
      "9     2020-08-21       11773470.0      LAKE  2020-08-22  34.678611   \n",
      "10    2020-08-22       11773470.0      LAKE  2020-08-23  34.678611   \n",
      "11    2020-08-29       11773470.0      LAKE  2020-08-30  34.678611   \n",
      "\n",
      "      Lon Fire  Number of NEW VIIRS points   NEW FRP  \\\n",
      "0  -118.451944                       132.0    782.77   \n",
      "1  -118.451944                        25.0   1644.50   \n",
      "2  -118.451944                        70.0  11606.51   \n",
      "3  -118.451944                        34.0   7911.41   \n",
      "4  -118.451944                        28.0   1806.03   \n",
      "5  -118.451944                       133.0   2547.34   \n",
      "6  -118.451944                        32.0   1936.13   \n",
      "7  -118.451944                        55.0   3272.50   \n",
      "8  -118.451944                        63.0   1469.15   \n",
      "9  -118.451944                        54.0   2983.50   \n",
      "10 -118.451944                         4.0     34.50   \n",
      "11 -118.451944                         1.0      1.74   \n",
      "\n",
      "                                             geometry  fire area (ha)  \n",
      "0   MULTIPOLYGON (((3641986.585 323212.339, 364197...     2056.378485  \n",
      "1   MULTIPOLYGON (((3630083.512 322187.932, 363007...      196.114730  \n",
      "2   MULTIPOLYGON (((3631093.725 323487.926, 363109...      796.663316  \n",
      "3   MULTIPOLYGON (((3629744.627 321900.201, 362973...      918.180196  \n",
      "4   MULTIPOLYGON (((3627559.548 324615.168, 362755...      445.839030  \n",
      "5   MULTIPOLYGON (((3633424.529 326832.891, 363342...     2461.323352  \n",
      "6   MULTIPOLYGON (((3627744.130 324262.296, 362773...      431.101382  \n",
      "7   MULTIPOLYGON (((3628041.297 324222.835, 362803...      796.799837  \n",
      "8   MULTIPOLYGON (((3626573.771 331082.596, 362656...     1017.305845  \n",
      "9   MULTIPOLYGON (((3626799.236 325038.628, 362679...      632.931011  \n",
      "10  MULTIPOLYGON (((3625516.379 324486.136, 362550...       27.908175  \n",
      "11  POLYGON ((3633778.944 329023.363, 3633772.010 ...        0.094198  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lthapa/anaconda3/envs/ML_py/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/lthapa/anaconda3/envs/ML_py/lib/python3.7/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/lthapa/anaconda3/envs/ML_py/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#2020 fires\n",
    "#fire_incidents = ['AUGUST COMPLEX','BOBCAT', 'DOLAN', 'HOLIDAY FARM','CREEK', 'LAKE', 'CAMERON PEAK', 'PINE GULCH']\n",
    "#fire_incidents=['BOBCAT', 'DOLAN', 'HOLIDAY FARM','CREEK', 'LAKE', 'CAMERON PEAK', 'PINE GULCH']\n",
    "fire_incidents = ['LAKE']\n",
    "\n",
    "path_poly = '/data2/lthapa/ML_daily/fire_polygons/'\n",
    "suffix_poly = 'Z_day_start.geojson'\n",
    "day_start_hour=12\n",
    "for jj in range(len(fire_incidents)):\n",
    "    fire_name = fire_incidents[jj].lower().replace(' ','_')\n",
    "    print(path_poly+fire_name+'_VIIRS_daily_'+str(day_start_hour)+suffix_poly)\n",
    "    fire_daily = gpd.read_file(path_poly+fire_name+'_VIIRS_daily_'+str(day_start_hour)+suffix_poly)\n",
    "    fire_daily=fire_daily.drop(columns=['Current Overpass'])\n",
    "    fire_daily = fire_daily.drop(np.where(fire_daily['geometry']==None)[0])\n",
    "    fire_daily['fire area (ha)'] = fire_daily['geometry'].area/10000 #hectares\n",
    "    fire_daily.set_geometry(col='geometry', inplace=True) #designate the geometry column\n",
    "    fire_daily = fire_daily.rename(columns={'Current Day':'UTC Day', 'Local Day': str(day_start_hour)+ 'Z Start Day'})\n",
    "    \n",
    "    fire_daily = fire_daily.iloc[np.array(fire_daily['UTC Day'].values,dtype='datetime64')<=np.datetime64('2020-10-31'),:]\n",
    "\n",
    "    #print(sit209_data[sit209_data['INC_IDENTIFIER']==fire_daily['Incident Number'].iloc[0]])\n",
    "    #get the fire incident number, lat, and lon\n",
    "    incident_number = fire_daily['Incident Number'].iloc[0]\n",
    "    fire_lat = fire_daily['Lat Fire'].iloc[0]\n",
    "    fire_lon = fire_daily['Lon Fire'].iloc[0]\n",
    "    print(incident_number, fire_lat, fire_lon)\n",
    "    \n",
    "    sit209_data_fire = sit209_data[sit209_data['INC_IDENTIFIER']==incident_number]\n",
    "    \n",
    "    #do the time zone conversion\n",
    "    obj=TimezoneFinder() #initialize the timezone finder\n",
    "    tz = obj.timezone_at(lng=fire_lon, lat=fire_lat) #get the timezone\n",
    "    local = pytz.timezone(tz)\n",
    "    utc = pytz.utc\n",
    "    \n",
    "    \n",
    "    #put the start and end times in local time\n",
    "    loc_dt_start = [local.localize(datetime.strptime(date, '%m/%d/%Y %H:%M:%S %p')) for date in sit209_data_fire['REPORT_FROM_DATE'].values]\n",
    "    loc_dt_end = [local.localize(datetime.strptime(date, '%m/%d/%Y %H:%M:%S %p')) for date in sit209_data_fire['REPORT_TO_DATE'].values]\n",
    "    \n",
    "    #put them in UTC time\n",
    "    utc_dt_start = [time_start.astimezone(utc) for time_start in loc_dt_start]\n",
    "    utc_dt_end = [time_end.astimezone(utc) for time_end in loc_dt_end]\n",
    "    \n",
    "    start_day = pd.to_datetime(utc_dt_start[0]).strftime('%Y-%m-%d')+' '+str(day_start_hour)+':00'\n",
    "    \n",
    "    \n",
    "    #reassign to UTC time, this DOES keep track of daylight savings (eg +7 is used for PDT, +8 is used for PST)\n",
    "    sit209_data_fire['Report Start UTC'] = pd.to_datetime(utc_dt_start)\n",
    "    sit209_data_fire['Report End UTC'] = pd.to_datetime(utc_dt_end)\n",
    "    sit209_data_fire['Timezone']= tz\n",
    "    \n",
    "    #localise the index\n",
    "    sit209_data_fire = sit209_data_fire.set_index(['Report Start UTC']).tz_localize(None)\n",
    "    #print(sit209_data_fire.iloc[0:4])\n",
    "    \n",
    "    \n",
    "    ## do the 12z-12z day grouping, based on the UTC times\n",
    "    start_day_utc = str(utc_dt_start[0])\n",
    "    start_datetime_utc = np.datetime64(start_day_utc[0:10]+'T'+str(day_start_hour).zfill(2)+':00')   \n",
    "    #sit209_data_fire = sit209_data_fire.resample('24H',origin=start_datetime_utc)\n",
    "\n",
    "    personnel = sit209_data_fire['RESOURCE_PERSONNEL'].resample('24H',origin=start_datetime_utc).sum().reset_index()\n",
    "    percent_contained = sit209_data_fire['PCT_CONTAINED_COMPLETED'].resample('24H',origin=start_datetime_utc).mean().reset_index()\n",
    "    \n",
    "    df_sit209 = pd.concat([percent_contained,personnel.drop(columns='Report Start UTC')],axis=1)\n",
    "    df_sit209.columns=['day', 'percent_contained', 'personnel']\n",
    "    df_sit209['day'] = pd.to_datetime(df_sit209['day'].values).strftime('%Y-%m-%d')\n",
    "    inds = df_sit209['day'].isin(fire_daily[str(day_start_hour)+'Z Start Day']).values\n",
    "    print(inds)\n",
    "    print(df_sit209.iloc[inds])\n",
    "    print(fire_daily)\n",
    "    \n",
    "    #day = np.datetime64(str(utc_dt_start[0])[0:10]+'T'+str(day_start_hour).zfill(2)+':00',\n",
    "    #                   str(utc_dt_start[len(utc_dt_start)-1])[0:10]+'T'+str(day_start_hour).zfill(2)+':00')\n",
    "    #print(str(utc_dt_start[0])[0:10]+'T'+str(day_start_hour).zfill(2)+':00')\n",
    "    #print(str(utc_dt_start[len(utc_dt_start)-1])[0:10]+'T'+str(day_start_hour).zfill(2)+':00')\n",
    "    #df_sit209 = pd.DataFrame({'day':day,'personnel':personnel,'percent_contained':percent_contained})\n",
    "    #print(df_sit209)\n",
    "    \n",
    "    \"\"\"\n",
    "    sit209_data_fire = sit209_data_fire.set_index(['Report Start UTC'])     \n",
    "    #print(sit209_data_fire)\n",
    "    \n",
    "    #grab the resources and percent contained\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1364adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "efe6eaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pd.to_datetime(utc_dt_start)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdbf2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
