{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db3e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.set_option('display.max_rows', None)\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "np.set_printoptions(threshold=100000)\n",
    "from shapely.geometry import Polygon, Point, MultiPoint\n",
    "from shapely.ops import cascaded_union\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import metpy.calc as mc\n",
    "from metpy.units import units\n",
    "\n",
    "from my_functions import sat_vap_press, vap_press, hot_dry_windy, haines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8e236",
   "metadata": {},
   "source": [
    "## Load in and concatenate the feature vectors\n",
    "This will concatenate met/precip from today and labels for today and tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a8f64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndays = 2\n",
    "feat_fuels = pd.read_csv('fire_features_fuels.csv') #fccs\n",
    "feat_merra = pd.read_csv('fire_features_merra_1dayout.csv') #merra \n",
    "feat_precip = pd.read_csv('fire_features_precip_1dayout_day0poly.csv') #precip\n",
    "\n",
    "labels_pm25 = pd.read_csv('fire_labels_1dayout_day0poly.csv') #labels (12Z PM2.5 rates from QFED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e539f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Incident Number', 'Fire Name', 'Current Day', 'Lat Fire', 'Lon Fire',\n",
       "       'Number of VIIRS points', 'TLML_12Z_0', 'QLML_12Z_0', 'SPEEDLML_12Z_0',\n",
       "       'PS_12Z_0', 'T_12Z_700mb_0', 'T_12Z_500mb_0', 'QV_12Z_700mb_0',\n",
       "       'PBLH_12Z_0', 'TCZPBL_12Z_0', 'TLML_12Z_1', 'QLML_12Z_1',\n",
       "       'SPEEDLML_12Z_1', 'PS_12Z_1', 'T_12Z_700mb_1', 'T_12Z_500mb_1',\n",
       "       'QV_12Z_700mb_1', 'PBLH_12Z_1', 'TCZPBL_12Z_1', 'fccs', 'slp', 'asp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull fccs, slp and aspect out of the fuels csv (static feature vector)\n",
    "feat_add = feat_fuels.loc[:,['fccs', 'slp', 'asp']]\n",
    "fire_features = pd.concat((feat_merra, feat_add), axis=1)\n",
    "fire_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f83c57b4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Incident Number', 'Fire Name', 'Current Day', 'Lat Fire', 'Lon Fire',\n",
       "       'Number of VIIRS points', 'TLML_12Z_0', 'QLML_12Z_0', 'SPEEDLML_12Z_0',\n",
       "       'PS_12Z_0', 'T_12Z_700mb_0', 'T_12Z_500mb_0', 'QV_12Z_700mb_0',\n",
       "       'PBLH_12Z_0', 'TCZPBL_12Z_0', 'TLML_12Z_1', 'QLML_12Z_1',\n",
       "       'SPEEDLML_12Z_1', 'PS_12Z_1', 'T_12Z_700mb_1', 'T_12Z_500mb_1',\n",
       "       'QV_12Z_700mb_1', 'PBLH_12Z_1', 'TCZPBL_12Z_1', 'fccs', 'slp', 'asp',\n",
       "       'precip_0', 'precip_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dy in range(ndays):\n",
    "    #combine the two precip names into one\n",
    "    precip = feat_precip[['A_PCP_GDS5_SFC_acc24h_'+str(dy), 'APCP_P8_L1_GST0_acc_'+str(dy)]].values #just need to add the _0 and _1 when I have that vector done\n",
    "    precip = np.nanmax(precip, axis=1)\n",
    "    feat_add = pd.DataFrame({'precip_'+str(dy): precip})\n",
    "    fire_features = pd.concat((fire_features, feat_add), axis=1)\n",
    "fire_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33b7c0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Drop the zero features (not sure the best way to do this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f86a8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inds = np.where(fire_features['QV_12Z_700mb']==0) #here's where we drop the zero features\n",
    "features = fire_features.drop(labels=inds[0], axis=0)\n",
    "features = features.reset_index(drop=True) #reset the indices beecause we dropped some\n",
    "\n",
    "\n",
    "labels = labels_pm25.drop(labels=inds[0], axis=0)\n",
    "labels = labels.reset_index(drop=True)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177348c5",
   "metadata": {},
   "source": [
    "## Hot-Dry-Windy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a434ebe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/lthapa/ML_daily/my_functions.py:12: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  *(53.878-1331.22/T-9.44523*np.log(T)+0.014025*T))/101325*1013.25 # hPa\n",
      "/data2/lthapa/ML_daily/my_functions.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  *(53.878-1331.22/T-9.44523*np.log(T)+0.014025*T))/101325*1013.25 # hPa\n",
      "/data2/lthapa/ML_daily/my_functions.py:12: RuntimeWarning: invalid value encountered in subtract\n",
      "  *(53.878-1331.22/T-9.44523*np.log(T)+0.014025*T))/101325*1013.25 # hPa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Incident Number', 'Fire Name', 'Current Day', 'Lat Fire', 'Lon Fire',\n",
       "       'Number of VIIRS points', 'TLML_12Z_0', 'QLML_12Z_0', 'SPEEDLML_12Z_0',\n",
       "       'PS_12Z_0', 'T_12Z_700mb_0', 'T_12Z_500mb_0', 'QV_12Z_700mb_0',\n",
       "       'PBLH_12Z_0', 'TCZPBL_12Z_0', 'TLML_12Z_1', 'QLML_12Z_1',\n",
       "       'SPEEDLML_12Z_1', 'PS_12Z_1', 'T_12Z_700mb_1', 'T_12Z_500mb_1',\n",
       "       'QV_12Z_700mb_1', 'PBLH_12Z_1', 'TCZPBL_12Z_1', 'fccs', 'slp', 'asp',\n",
       "       'precip_0', 'precip_1', 'ESATLML_12Z_0', 'ELML_12Z_0', 'HDWLML_0',\n",
       "       'RHLML_12Z_0', 'ESATLML_12Z_1', 'ELML_12Z_1', 'HDWLML_1',\n",
       "       'RHLML_12Z_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dy in range(ndays):\n",
    "    # calculate the hot-dry-windy and related variables\n",
    "    esat = sat_vap_press(fire_features['TLML_12Z_'+str(dy)].values)\n",
    "    e = vap_press(fire_features['QLML_12Z_'+str(dy)].values, fire_features['PS_12Z_'+str(dy)].values)\n",
    "    hdw = hot_dry_windy(e, esat, fire_features['SPEEDLML_12Z_'+str(dy)].values)\n",
    "    rh = e/esat\n",
    "    #append them to the dataframe\n",
    "    df_hdw = pd.DataFrame({'ESATLML_12Z_'+str(dy):esat, 'ELML_12Z_'+str(dy):e, 'HDWLML_'+str(dy):hdw, 'RHLML_12Z_'+str(dy): rh})\n",
    "    fire_features = pd.concat([fire_features, df_hdw], axis=1)\n",
    "fire_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83808808",
   "metadata": {},
   "source": [
    "## Haines Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dda979d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lthapa/anaconda3/envs/ML_py/lib/python3.7/site-packages/pint/numpy_func.py:303: RuntimeWarning: divide by zero encountered in log\n",
      "  result_magnitude = func(*stripped_args, **stripped_kwargs)\n",
      "/home/lthapa/anaconda3/envs/ML_py/lib/python3.7/site-packages/pint/quantity.py:1237: RuntimeWarning: invalid value encountered in true_divide\n",
      "  magnitude = magnitude_op(new_self._magnitude, other._magnitude)\n",
      "/data2/lthapa/ML_daily/my_functions.py:47: RuntimeWarning: invalid value encountered in less_equal\n",
      "  B_cat[(B<=14)] = 1 # B_cat = 1 when B<=14\n",
      "/data2/lthapa/ML_daily/my_functions.py:48: RuntimeWarning: invalid value encountered in greater\n",
      "  B_cat[(B>14) & (B<21)] = 2 # B_cat = 2 when B>14 and B<21\n",
      "/data2/lthapa/ML_daily/my_functions.py:48: RuntimeWarning: invalid value encountered in less\n",
      "  B_cat[(B>14) & (B<21)] = 2 # B_cat = 2 when B>14 and B<21\n",
      "/data2/lthapa/ML_daily/my_functions.py:49: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  B_cat[(B>=21)] = 3 # B_cat = 3 when B>=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8161,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lthapa/anaconda3/envs/ML_py/lib/python3.7/site-packages/pint/numpy_func.py:303: RuntimeWarning: divide by zero encountered in log\n",
      "  result_magnitude = func(*stripped_args, **stripped_kwargs)\n",
      "/home/lthapa/anaconda3/envs/ML_py/lib/python3.7/site-packages/pint/quantity.py:1237: RuntimeWarning: invalid value encountered in true_divide\n",
      "  magnitude = magnitude_op(new_self._magnitude, other._magnitude)\n",
      "/data2/lthapa/ML_daily/my_functions.py:47: RuntimeWarning: invalid value encountered in less_equal\n",
      "  B_cat[(B<=14)] = 1 # B_cat = 1 when B<=14\n",
      "/data2/lthapa/ML_daily/my_functions.py:48: RuntimeWarning: invalid value encountered in greater\n",
      "  B_cat[(B>14) & (B<21)] = 2 # B_cat = 2 when B>14 and B<21\n",
      "/data2/lthapa/ML_daily/my_functions.py:48: RuntimeWarning: invalid value encountered in less\n",
      "  B_cat[(B>14) & (B<21)] = 2 # B_cat = 2 when B>14 and B<21\n",
      "/data2/lthapa/ML_daily/my_functions.py:49: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  B_cat[(B>=21)] = 3 # B_cat = 3 when B>=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8161,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Incident Number', 'Fire Name', 'Current Day', 'Lat Fire', 'Lon Fire',\n",
       "       'Number of VIIRS points', 'TLML_12Z_0', 'QLML_12Z_0', 'SPEEDLML_12Z_0',\n",
       "       'PS_12Z_0', 'T_12Z_700mb_0', 'T_12Z_500mb_0', 'QV_12Z_700mb_0',\n",
       "       'PBLH_12Z_0', 'TCZPBL_12Z_0', 'TLML_12Z_1', 'QLML_12Z_1',\n",
       "       'SPEEDLML_12Z_1', 'PS_12Z_1', 'T_12Z_700mb_1', 'T_12Z_500mb_1',\n",
       "       'QV_12Z_700mb_1', 'PBLH_12Z_1', 'TCZPBL_12Z_1', 'fccs', 'slp', 'asp',\n",
       "       'precip_0', 'precip_1', 'ESATLML_12Z_0', 'ELML_12Z_0', 'HDWLML_0',\n",
       "       'RHLML_12Z_0', 'ESATLML_12Z_1', 'ELML_12Z_1', 'HDWLML_1', 'RHLML_12Z_1',\n",
       "       'Td_12Z_700mb_0', 'E_700mb_0', 'HAINES_0', 'Td_12Z_700mb_1',\n",
       "       'E_700mb_1', 'HAINES_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the Haines and related variables\n",
    "\n",
    "for dy in range(ndays):\n",
    "\n",
    "    #vapor pressure at 700mb\n",
    "    e_hPa_700 = vap_press(fire_features['QV_12Z_700mb_'+str(dy)].values, 700*np.ones(fire_features['QV_12Z_700mb_'+str(dy)].values.shape)) # hPa\n",
    "    e_hPa_700 = units.Quantity(e_hPa_700, \"hPa\")\n",
    "\n",
    "    #dewpoint at 700mb\n",
    "    td_700 = mc.dewpoint(e_hPa_700)\n",
    "    td_700 = np.array(td_700) # degrees C\n",
    "    print(td_700.shape)\n",
    "\n",
    "    haines_index = haines(fire_features['T_12Z_700mb_'+str(dy)].values, fire_features['T_12Z_500mb_'+str(dy)], td_700)\n",
    "\n",
    "    df_haines = pd.DataFrame({'Td_12Z_700mb_'+str(dy):td_700, 'E_700mb_'+str(dy):e_hPa_700, 'HAINES_'+str(dy): haines_index})\n",
    "\n",
    "    fire_features = pd.concat([fire_features, df_haines], axis=1)\n",
    "fire_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea32065",
   "metadata": {},
   "source": [
    "## Concatenate features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "605023c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Incident Number', 'Fire Name', 'Current Day', 'Lat Fire', 'Lon Fire',\n",
       "       'Number of VIIRS points', 'TLML_12Z_0', 'QLML_12Z_0', 'SPEEDLML_12Z_0',\n",
       "       'PS_12Z_0', 'T_12Z_700mb_0', 'T_12Z_500mb_0', 'QV_12Z_700mb_0',\n",
       "       'PBLH_12Z_0', 'TCZPBL_12Z_0', 'TLML_12Z_1', 'QLML_12Z_1',\n",
       "       'SPEEDLML_12Z_1', 'PS_12Z_1', 'T_12Z_700mb_1', 'T_12Z_500mb_1',\n",
       "       'QV_12Z_700mb_1', 'PBLH_12Z_1', 'TCZPBL_12Z_1', 'fccs', 'slp', 'asp',\n",
       "       'precip_0', 'precip_1', 'ESATLML_12Z_0', 'ELML_12Z_0', 'HDWLML_0',\n",
       "       'RHLML_12Z_0', 'ESATLML_12Z_1', 'ELML_12Z_1', 'HDWLML_1', 'RHLML_12Z_1',\n",
       "       'Td_12Z_700mb_0', 'E_700mb_0', 'HAINES_0', 'Td_12Z_700mb_1',\n",
       "       'E_700mb_1', 'HAINES_1', 'biomass_12Z_today', 'biomass_12Z_tomorrow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([fire_features, labels_pm25.loc[:,['biomass_12Z_today', 'biomass_12Z_tomorrow']]], axis=1)\n",
    "dataset.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1814ff",
   "metadata": {},
   "source": [
    "## Drop rows that contain nans and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972972e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 485,  539,  540,  541,  542,  688, 1131, 1665, 1666, 1667, 1668,\n",
      "       1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 2262, 2497, 2514,\n",
      "       2626, 2627, 2733, 2734, 2921, 2924, 2948, 3458, 4168, 4169, 4777,\n",
      "       4804, 5152, 5276, 5277, 5278, 5279, 5280, 5281, 5282, 5283, 5284,\n",
      "       5285, 5286, 5287, 5288, 5289, 5290, 5291, 5292, 5293, 5294, 6984,\n",
      "       6985, 6986, 6987, 6988, 7761, 7785, 7788, 7789, 7790, 7791, 8143]),)\n",
      "Index(['Incident Number', 'Fire Name', 'Current Day', 'Lat Fire', 'Lon Fire',\n",
      "       'Number of VIIRS points', 'TLML_12Z_0', 'QLML_12Z_0', 'SPEEDLML_12Z_0',\n",
      "       'PS_12Z_0', 'T_12Z_700mb_0', 'T_12Z_500mb_0', 'QV_12Z_700mb_0',\n",
      "       'PBLH_12Z_0', 'TCZPBL_12Z_0', 'TLML_12Z_1', 'QLML_12Z_1',\n",
      "       'SPEEDLML_12Z_1', 'PS_12Z_1', 'T_12Z_700mb_1', 'T_12Z_500mb_1',\n",
      "       'QV_12Z_700mb_1', 'PBLH_12Z_1', 'TCZPBL_12Z_1', 'fccs', 'slp', 'asp',\n",
      "       'precip_0', 'precip_1', 'ESATLML_12Z_0', 'ELML_12Z_0', 'HDWLML_0',\n",
      "       'RHLML_12Z_0', 'ESATLML_12Z_1', 'ELML_12Z_1', 'HDWLML_1', 'RHLML_12Z_1',\n",
      "       'Td_12Z_700mb_0', 'E_700mb_0', 'HAINES_0', 'Td_12Z_700mb_1',\n",
      "       'E_700mb_1', 'HAINES_1', 'biomass_12Z_today', 'biomass_12Z_tomorrow'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "is_NaN = dataset.isnull()\n",
    "row_has_NaN = np.where(is_NaN.any(axis=1))\n",
    "print(row_has_NaN)\n",
    "dataset =  dataset.drop(labels=row_has_NaN[0], axis=0)\n",
    "dataset = dataset.reset_index(drop=True) #reset the indices beecause we dropped some\n",
    "print(dataset.columns)\n",
    "\n",
    "dataset.to_csv('training_data_1day_forecast_day0poly.csv')\n",
    "#rows_with_NaN = df[row_has_NaN]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c54f62",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## KBDI (not finished yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023440f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "days=features['Current Day'].values\n",
    "print(days[0][0:4])\n",
    "days_reformatted= [days[jj][0:4]+days[jj][5:7]+days[jj][8:10] for jj in range(len(days))]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640fe2a4",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_in = pd.DataFrame({'date': days_reformatted, \n",
    "        'precip': features['precip'].values,\n",
    "         'temp': features['TLML_12Z'].values,\n",
    "         'rh': features['RHLML_12Z'].values,\n",
    "        'wind': features['SPEEDLML_12Z'].values})\n",
    "df_in.to_csv('KBDI_IN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1871cd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "command = 'kbdi-ffdi-run -i /data2/lthapa/ML_daily/KBDI_IN.csv'+' -o /data2/lthapa/ML_daily/KBDI_OUT.csv'\n",
    "print(command)\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e673d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_kbdi = pd.read_csv('KBDI_OUT.csv')\n",
    "kbdi = df_kbdi['KBDI']\n",
    "print(kbdi.values)\n",
    "\n",
    "features = pd.concat([features, kbdi], axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64bca85",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kbdi = np.zeros(len(features))\n",
    "for ii in range(1):#len(features)):\n",
    "    df_in = pd.DataFrame({'date': days_reformatted[ii], \n",
    "        'precip': features.loc[ii, 'precip'],\n",
    "         'temp': features.loc[ii, 'TLML_12Z'],\n",
    "         'rh': features.loc[ii, 'RHLML_12Z'],\n",
    "        'wind': features.loc[ii, 'SPEEDLML_12Z']}, index=range(1))\n",
    "    print(df_in)\n",
    "    df_in.to_csv('/data2/lthapa/ML_daily/kbdi_ffdi_io/KBDI_IN_'+str(ii)+'.csv')\n",
    "    command = 'kbdi-ffdi-run -i /data2/lthapa/ML_daily/kbdi_ffdi_io/KBDI_IN_'+str(ii)+'.csv'+' -o /data2/lthapa/ML_daily/kbdi_ffdi_io/KBDI_OUT_'+str(ii)+'.csv'\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    df_kbdi = pd.read_csv('/data2/lthapa/ML_daily/kbdi_ffdi_io/KBDI_OUT_'+str(ii)+'.csv')\n",
    "    print(df_kbdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7d249",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features.loc[0, 'precip']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c55f82c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Old code to concatenate precip vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f7789",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feat_precip_2019 = pd.read_csv('fire_features_precip_2019.csv') #2019 precip\n",
    "feat_precip_2020 = pd.read_csv('fire_features_precip_2020.csv') #2020 precip\n",
    "precip_2019 = feat_precip_2019['A_PCP_GDS5_SFC_acc24h'].values.reshape(-1, 1)\n",
    "precip_2020 = feat_precip_2020[['A_PCP_GDS5_SFC_acc24h','APCP_P8_L1_GST0_acc']].values\n",
    "precip = np.concatenate((precip_2019, precip_2020), axis=1)\n",
    "precip = np.nansum(precip, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
